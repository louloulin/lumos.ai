//! æ€§èƒ½ç›‘æ§ç³»ç»Ÿç¤ºä¾‹ - å±•ç¤ºLumosAIçš„æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–
//! 
//! è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ç›‘æ§Agentæ€§èƒ½ã€å·¥ä½œæµæ‰§è¡Œæ—¶é—´ã€å†…å­˜ä½¿ç”¨ç­‰æŒ‡æ ‡ã€‚
//! 
//! è¿è¡Œæ–¹å¼:
//! ```bash
//! cargo run --example performance_monitoring
//! ```

use lumosai_core::prelude::*;
use lumosai_core::llm::MockLlmProvider;
use lumosai_core::agent::AgentTrait; // æ­£ç¡®çš„Agent traitå¯¼å…¥
use std::sync::Arc;
use std::time::{Duration, Instant};
use std::collections::HashMap;
use anyhow::Result;
use tracing::{info, warn, error};
use serde::{Serialize, Deserialize};
use tokio::sync::RwLock;

/// æ€§èƒ½æŒ‡æ ‡
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceMetrics {
    pub agent_id: String,
    pub operation: String,
    pub duration: Duration,
    pub memory_usage: u64,
    pub cpu_usage: f64,
    pub success: bool,
    pub timestamp: chrono::DateTime<chrono::Utc>,
    pub metadata: HashMap<String, String>,
}

/// æ€§èƒ½ç›‘æ§å™¨
#[derive(Debug)]
pub struct PerformanceMonitor {
    metrics: Arc<RwLock<Vec<PerformanceMetrics>>>,
    thresholds: PerformanceThresholds,
    alerts: Arc<RwLock<Vec<PerformanceAlert>>>,
}

/// æ€§èƒ½é˜ˆå€¼é…ç½®
#[derive(Debug, Clone)]
pub struct PerformanceThresholds {
    pub max_response_time: Duration,
    pub max_memory_usage: u64,
    pub max_cpu_usage: f64,
    pub min_success_rate: f64,
}

/// æ€§èƒ½è­¦æŠ¥
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceAlert {
    pub alert_type: AlertType,
    pub message: String,
    pub severity: AlertSeverity,
    pub timestamp: chrono::DateTime<chrono::Utc>,
    pub agent_id: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AlertType {
    HighResponseTime,
    HighMemoryUsage,
    HighCpuUsage,
    LowSuccessRate,
    SystemOverload,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AlertSeverity {
    Info,
    Warning,
    Critical,
}

impl PerformanceMonitor {
    pub fn new() -> Self {
        Self {
            metrics: Arc::new(RwLock::new(Vec::new())),
            thresholds: PerformanceThresholds {
                max_response_time: Duration::from_secs(5),
                max_memory_usage: 1024 * 1024 * 100, // 100MB
                max_cpu_usage: 80.0,
                min_success_rate: 0.95,
            },
            alerts: Arc::new(RwLock::new(Vec::new())),
        }
    }

    /// è®°å½•æ€§èƒ½æŒ‡æ ‡
    pub async fn record_metric(&self, metric: PerformanceMetrics) {
        // æ£€æŸ¥æ˜¯å¦è¶…è¿‡é˜ˆå€¼
        self.check_thresholds(&metric).await;
        
        // å­˜å‚¨æŒ‡æ ‡
        let mut metrics = self.metrics.write().await;
        metrics.push(metric);
        
        // ä¿æŒæœ€è¿‘1000æ¡è®°å½•
        if metrics.len() > 1000 {
            let excess = metrics.len() - 1000;
            metrics.drain(0..excess);
        }
    }

    /// æ£€æŸ¥æ€§èƒ½é˜ˆå€¼
    async fn check_thresholds(&self, metric: &PerformanceMetrics) {
        let mut alerts = Vec::new();

        // æ£€æŸ¥å“åº”æ—¶é—´
        if metric.duration > self.thresholds.max_response_time {
            alerts.push(PerformanceAlert {
                alert_type: AlertType::HighResponseTime,
                message: format!("Agent {} å“åº”æ—¶é—´è¿‡é•¿: {:?}", metric.agent_id, metric.duration),
                severity: AlertSeverity::Warning,
                timestamp: chrono::Utc::now(),
                agent_id: metric.agent_id.clone(),
            });
        }

        // æ£€æŸ¥å†…å­˜ä½¿ç”¨
        if metric.memory_usage > self.thresholds.max_memory_usage {
            alerts.push(PerformanceAlert {
                alert_type: AlertType::HighMemoryUsage,
                message: format!("Agent {} å†…å­˜ä½¿ç”¨è¿‡é«˜: {} MB", 
                    metric.agent_id, metric.memory_usage / 1024 / 1024),
                severity: AlertSeverity::Critical,
                timestamp: chrono::Utc::now(),
                agent_id: metric.agent_id.clone(),
            });
        }

        // æ£€æŸ¥CPUä½¿ç”¨
        if metric.cpu_usage > self.thresholds.max_cpu_usage {
            alerts.push(PerformanceAlert {
                alert_type: AlertType::HighCpuUsage,
                message: format!("Agent {} CPUä½¿ç”¨è¿‡é«˜: {:.1}%", metric.agent_id, metric.cpu_usage),
                severity: AlertSeverity::Warning,
                timestamp: chrono::Utc::now(),
                agent_id: metric.agent_id.clone(),
            });
        }

        // å­˜å‚¨è­¦æŠ¥
        if !alerts.is_empty() {
            let mut alert_storage = self.alerts.write().await;
            alert_storage.extend(alerts);
        }
    }

    /// è·å–æ€§èƒ½ç»Ÿè®¡
    pub async fn get_performance_stats(&self, agent_id: Option<&str>) -> PerformanceStats {
        let metrics = self.metrics.read().await;
        let filtered_metrics: Vec<_> = metrics.iter()
            .filter(|m| agent_id.map_or(true, |id| m.agent_id == id))
            .collect();

        if filtered_metrics.is_empty() {
            return PerformanceStats::default();
        }

        let total_requests = filtered_metrics.len();
        let successful_requests = filtered_metrics.iter().filter(|m| m.success).count();
        let success_rate = successful_requests as f64 / total_requests as f64;

        let avg_response_time = filtered_metrics.iter()
            .map(|m| m.duration.as_millis() as f64)
            .sum::<f64>() / total_requests as f64;

        let avg_memory_usage = filtered_metrics.iter()
            .map(|m| m.memory_usage as f64)
            .sum::<f64>() / total_requests as f64;

        let avg_cpu_usage = filtered_metrics.iter()
            .map(|m| m.cpu_usage)
            .sum::<f64>() / total_requests as f64;

        PerformanceStats {
            total_requests,
            successful_requests,
            success_rate,
            avg_response_time_ms: avg_response_time,
            avg_memory_usage_mb: avg_memory_usage / 1024.0 / 1024.0,
            avg_cpu_usage_percent: avg_cpu_usage,
        }
    }

    /// è·å–æœ€è¿‘çš„è­¦æŠ¥
    pub async fn get_recent_alerts(&self, limit: usize) -> Vec<PerformanceAlert> {
        let alerts = self.alerts.read().await;
        alerts.iter()
            .rev()
            .take(limit)
            .cloned()
            .collect()
    }
}

/// æ€§èƒ½ç»Ÿè®¡
#[derive(Debug, Default, Serialize, Deserialize)]
pub struct PerformanceStats {
    pub total_requests: usize,
    pub successful_requests: usize,
    pub success_rate: f64,
    pub avg_response_time_ms: f64,
    pub avg_memory_usage_mb: f64,
    pub avg_cpu_usage_percent: f64,
}

/// æ€§èƒ½ç›‘æ§è£…é¥°å™¨
pub struct MonitoredAgent {
    agent: Box<dyn AgentTrait>,
    monitor: Arc<PerformanceMonitor>,
    agent_id: String,
}

impl MonitoredAgent {
    pub fn new(agent: Box<dyn AgentTrait>, monitor: Arc<PerformanceMonitor>) -> Self {
        let agent_id = agent.get_name().to_string();
        Self {
            agent,
            monitor,
            agent_id,
        }
    }
}

impl MonitoredAgent {
    /// ç›‘æ§Agentçš„generateæ–¹æ³•
    pub async fn generate_monitored(&self, input: &str) -> Result<String> {
        let start_time = Instant::now();
        let start_memory = get_memory_usage();
        let start_cpu = get_cpu_usage();

        let result = self.agent.generate_simple(input).await;

        let duration = start_time.elapsed();
        let end_memory = get_memory_usage();
        let end_cpu = get_cpu_usage();

        let metric = PerformanceMetrics {
            agent_id: self.agent_id.clone(),
            operation: "generate".to_string(),
            duration,
            memory_usage: end_memory.saturating_sub(start_memory),
            cpu_usage: (end_cpu - start_cpu).max(0.0),
            success: result.is_ok(),
            timestamp: chrono::Utc::now(),
            metadata: HashMap::new(),
        };

        self.monitor.record_metric(metric).await;

        result.map_err(|e| anyhow::Error::new(e))
    }
}

#[tokio::main]
async fn main() -> Result<()> {
    // åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::INFO)
        .init();

    info!("ğŸ“Š LumosAI æ€§èƒ½ç›‘æ§ç¤ºä¾‹");
    println!("========================");

    // åˆ›å»ºLLMæä¾›è€…
    let llm = Arc::new(MockLlmProvider::new(vec![
        "æˆ‘æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚...".to_string(),
        "è®¡ç®—å®Œæˆï¼Œç»“æœå¦‚ä¸‹...".to_string(),
        "æ•°æ®åˆ†æå·²å®Œæˆ...".to_string(),
        "ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ...".to_string(),
    ]));

    // 1. åˆ›å»ºæ€§èƒ½ç›‘æ§å™¨
    println!("\n1ï¸âƒ£ åˆ›å»ºæ€§èƒ½ç›‘æ§å™¨");
    println!("------------------");

    let monitor = Arc::new(PerformanceMonitor::new());
    info!("âœ… æ€§èƒ½ç›‘æ§å™¨åˆ›å»ºæˆåŠŸ");

    // 2. åˆ›å»ºè¢«ç›‘æ§çš„Agent
    println!("\n2ï¸âƒ£ åˆ›å»ºè¢«ç›‘æ§çš„Agent");
    println!("--------------------");

    let base_agent = quick_agent("performance_test", "æ€§èƒ½æµ‹è¯•åŠ©æ‰‹")
        .model(llm.clone())
        .tools(vec![calculator(), time_tool(), web_search()])
        .build()?;

    let monitored_agent = MonitoredAgent::new(Box::new(base_agent), monitor.clone());
    info!("âœ… ç›‘æ§Agentåˆ›å»ºæˆåŠŸ");

    // 3. æ‰§è¡Œæ€§èƒ½æµ‹è¯•
    println!("\n3ï¸âƒ£ æ‰§è¡Œæ€§èƒ½æµ‹è¯•");
    println!("----------------");

    let test_queries = vec![
        "è®¡ç®— 123 + 456",
        "è·å–å½“å‰æ—¶é—´",
        "æœç´¢äººå·¥æ™ºèƒ½ç›¸å…³ä¿¡æ¯",
        "æ‰§è¡Œå¤æ‚è®¡ç®—ä»»åŠ¡",
        "å¤„ç†å¤§é‡æ•°æ®",
    ];

    for (i, query) in test_queries.iter().enumerate() {
        info!("ğŸ”„ æ‰§è¡Œæµ‹è¯• {}/{}: {}", i + 1, test_queries.len(), query);
        
        match monitored_agent.generate_monitored(query).await {
            Ok(response) => {
                info!("âœ… æµ‹è¯•æˆåŠŸ: {}", response);
            }
            Err(e) => {
                error!("âŒ æµ‹è¯•å¤±è´¥: {}", e);
            }
        }

        // æ·»åŠ ä¸€äº›å»¶è¿Ÿæ¥æ¨¡æ‹ŸçœŸå®ä½¿ç”¨
        tokio::time::sleep(Duration::from_millis(500)).await;
    }

    // 4. æŸ¥çœ‹æ€§èƒ½ç»Ÿè®¡
    println!("\n4ï¸âƒ£ æ€§èƒ½ç»Ÿè®¡åˆ†æ");
    println!("----------------");

    let stats = monitor.get_performance_stats(Some("performance_test")).await;
    info!("ğŸ“Š æ€§èƒ½ç»Ÿè®¡:");
    info!("   - æ€»è¯·æ±‚æ•°: {}", stats.total_requests);
    info!("   - æˆåŠŸè¯·æ±‚æ•°: {}", stats.successful_requests);
    info!("   - æˆåŠŸç‡: {:.2}%", stats.success_rate * 100.0);
    info!("   - å¹³å‡å“åº”æ—¶é—´: {:.2}ms", stats.avg_response_time_ms);
    info!("   - å¹³å‡å†…å­˜ä½¿ç”¨: {:.2}MB", stats.avg_memory_usage_mb);
    info!("   - å¹³å‡CPUä½¿ç”¨: {:.2}%", stats.avg_cpu_usage_percent);

    // 5. æ£€æŸ¥æ€§èƒ½è­¦æŠ¥
    println!("\n5ï¸âƒ£ æ€§èƒ½è­¦æŠ¥æ£€æŸ¥");
    println!("----------------");

    let alerts = monitor.get_recent_alerts(10).await;
    if alerts.is_empty() {
        info!("âœ… æ²¡æœ‰æ€§èƒ½è­¦æŠ¥");
    } else {
        warn!("âš ï¸ å‘ç°{}ä¸ªæ€§èƒ½è­¦æŠ¥:", alerts.len());
        for alert in &alerts {
            let severity_icon = match alert.severity {
                AlertSeverity::Info => "â„¹ï¸",
                AlertSeverity::Warning => "âš ï¸",
                AlertSeverity::Critical => "ğŸš¨",
            };
            info!("   {} {}: {}", severity_icon, alert.agent_id, alert.message);
        }
    }

    // 6. å‹åŠ›æµ‹è¯•
    println!("\n6ï¸âƒ£ å‹åŠ›æµ‹è¯•");
    println!("------------");

    info!("ğŸ”¥ å¼€å§‹å‹åŠ›æµ‹è¯•...");
    let stress_start = Instant::now();
    
    let mut handles = Vec::new();
    for i in 0..10 {
        let agent = MonitoredAgent::new(
            Box::new(quick_agent(&format!("stress_test_{}", i), "å‹åŠ›æµ‹è¯•åŠ©æ‰‹")
                .model(llm.clone())
                .tools(vec![calculator()])
                .build()?),
            monitor.clone()
        );
        
        let handle = tokio::spawn(async move {
            for j in 0..5 {
                let query = format!("è®¡ç®— {} * {}", i, j);
                let _ = agent.generate_monitored(&query).await;
            }
        });
        
        handles.push(handle);
    }

    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    for handle in handles {
        handle.await?;
    }

    let stress_duration = stress_start.elapsed();
    info!("âœ… å‹åŠ›æµ‹è¯•å®Œæˆï¼Œè€—æ—¶: {:?}", stress_duration);

    // 7. æœ€ç»ˆç»Ÿè®¡
    println!("\n7ï¸âƒ£ æœ€ç»ˆç»Ÿè®¡");
    println!("------------");

    let final_stats = monitor.get_performance_stats(None).await;
    info!("ğŸ“ˆ æœ€ç»ˆæ€§èƒ½ç»Ÿè®¡:");
    info!("   - æ€»è¯·æ±‚æ•°: {}", final_stats.total_requests);
    info!("   - æˆåŠŸç‡: {:.2}%", final_stats.success_rate * 100.0);
    info!("   - å¹³å‡å“åº”æ—¶é—´: {:.2}ms", final_stats.avg_response_time_ms);

    let final_alerts = monitor.get_recent_alerts(20).await;
    info!("ğŸš¨ æ€»è­¦æŠ¥æ•°: {}", final_alerts.len());

    // 8. æ€§èƒ½ä¼˜åŒ–å»ºè®®
    println!("\n8ï¸âƒ£ æ€§èƒ½ä¼˜åŒ–å»ºè®®");
    println!("----------------");

    generate_optimization_suggestions(&final_stats, &final_alerts);

    println!("\nğŸ‰ æ€§èƒ½ç›‘æ§ç¤ºä¾‹å®Œæˆ!");
    println!("\nğŸ“š ä¸‹ä¸€æ­¥å­¦ä¹ :");
    println!("   - examples/04_production/deployment.rs - éƒ¨ç½²æŒ‡å—");
    println!("   - docs/best-practices/performance.md - æ€§èƒ½ä¼˜åŒ–æœ€ä½³å®è·µ");

    Ok(())
}

/// è·å–å†…å­˜ä½¿ç”¨é‡ï¼ˆæ¨¡æ‹Ÿï¼‰
fn get_memory_usage() -> u64 {
    // åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šè·å–çœŸå®çš„å†…å­˜ä½¿ç”¨é‡
    use std::process;
    let pid = process::id();
    
    // æ¨¡æ‹Ÿå†…å­˜ä½¿ç”¨é‡
    (pid as u64 % 100) * 1024 * 1024 // 0-99MB
}

/// è·å–CPUä½¿ç”¨ç‡ï¼ˆæ¨¡æ‹Ÿï¼‰
fn get_cpu_usage() -> f64 {
    // åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œä¼šè·å–çœŸå®çš„CPUä½¿ç”¨ç‡
    use std::time::{SystemTime, UNIX_EPOCH};
    let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap();
    
    // æ¨¡æ‹ŸCPUä½¿ç”¨ç‡
    (now.as_millis() % 100) as f64
}

/// ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–å»ºè®®
fn generate_optimization_suggestions(stats: &PerformanceStats, alerts: &[PerformanceAlert]) {
    info!("ğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:");

    if stats.avg_response_time_ms > 1000.0 {
        info!("   - å“åº”æ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®ä¼˜åŒ–Agenté€»è¾‘æˆ–å¢åŠ ç¼“å­˜");
    }

    if stats.avg_memory_usage_mb > 50.0 {
        info!("   - å†…å­˜ä½¿ç”¨è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–å†…å­˜ç®¡ç†æˆ–å¢åŠ å†…å­˜é™åˆ¶");
    }

    if stats.success_rate < 0.95 {
        info!("   - æˆåŠŸç‡è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶");
    }

    let critical_alerts = alerts.iter()
        .filter(|a| matches!(a.severity, AlertSeverity::Critical))
        .count();
    
    if critical_alerts > 0 {
        info!("   - å‘ç°{}ä¸ªä¸¥é‡è­¦æŠ¥ï¼Œéœ€è¦ç«‹å³å¤„ç†", critical_alerts);
    }

    if stats.total_requests > 100 {
        info!("   - è¯·æ±‚é‡è¾ƒå¤§ï¼Œå»ºè®®è€ƒè™‘è´Ÿè½½å‡è¡¡å’Œæ°´å¹³æ‰©å±•");
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_performance_monitor() {
        let monitor = PerformanceMonitor::new();
        
        let metric = PerformanceMetrics {
            agent_id: "test_agent".to_string(),
            operation: "test".to_string(),
            duration: Duration::from_millis(100),
            memory_usage: 1024 * 1024, // 1MB
            cpu_usage: 10.0,
            success: true,
            timestamp: chrono::Utc::now(),
            metadata: HashMap::new(),
        };

        monitor.record_metric(metric).await;
        
        let stats = monitor.get_performance_stats(Some("test_agent")).await;
        assert_eq!(stats.total_requests, 1);
        assert_eq!(stats.successful_requests, 1);
        assert_eq!(stats.success_rate, 1.0);
    }

    #[tokio::test]
    async fn test_monitored_agent() {
        let llm = Arc::new(MockLlmProvider::new(vec!["Test response".to_string()]));
        let monitor = Arc::new(PerformanceMonitor::new());
        
        let base_agent = quick_agent("test", "Test agent")
            .model(llm)
            .build()
            .unwrap();
        
        let monitored_agent = MonitoredAgent::new(Box::new(base_agent), monitor.clone());
        
        let response = monitored_agent.generate("test query").await;
        assert!(response.is_ok());
        
        let stats = monitor.get_performance_stats(Some("test")).await;
        assert_eq!(stats.total_requests, 1);
    }
}
