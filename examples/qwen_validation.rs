use lumosai_core::llm::{QwenProvider, QwenApiType, LlmProvider, LlmOptions, Message, Role};
use std::time::Instant;

/// QwenéªŒè¯æµ‹è¯•
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸš€ LumosAI Qwen æä¾›å•†éªŒè¯æµ‹è¯•");
    println!("========================================");
    
    // æµ‹è¯•é…ç½®
    let api_key = "sk-bc977c4e31e542f1a34159cb42478198";
    let model = "qwen3-30b-a3b";
    
    // æµ‹è¯•1: DashScope API
    println!("\nğŸ“‹ æµ‹è¯•1: DashScope API");
    test_dashscope_api(api_key, model).await?;
    
    // æµ‹è¯•2: OpenAIå…¼å®¹API
    println!("\nğŸ“‹ æµ‹è¯•2: OpenAIå…¼å®¹API");
    test_openai_compatible_api(api_key, model).await?;
    
    println!("\nâœ… æ‰€æœ‰QwenéªŒè¯æµ‹è¯•å®Œæˆï¼");
    Ok(())
}

async fn test_dashscope_api(api_key: &str, model: &str) -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•DashScope APIå®ç°...");
    
    let provider = QwenProvider::new_with_api_type(
        api_key,
        model,
        "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation",
        QwenApiType::DashScope
    );
    
    // åŸºç¡€æ–‡æœ¬ç”Ÿæˆæµ‹è¯•
    let start_time = Instant::now();
    let result = provider.generate("ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚", &LlmOptions::default()).await;
    let duration = start_time.elapsed();
    
    match result {
        Ok(response) => {
            println!("âœ… DashScope APIè°ƒç”¨æˆåŠŸ!");
            println!("ğŸ“ å“åº”å†…å®¹: {}", response);
            println!("â±ï¸ å“åº”æ—¶é—´: {:?}", duration);
        }
        Err(e) => {
            println!("âŒ DashScope APIè°ƒç”¨å¤±è´¥: {}", e);
            return Err(format!("DashScope APIæµ‹è¯•å¤±è´¥: {}", e).into());
        }
    }
    
    // å¤šè½®å¯¹è¯æµ‹è¯•
    let messages = vec![
        Message {
            role: Role::System,
            content: "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚".to_string(),
            metadata: None,
            name: None,
        },
        Message {
            role: Role::User,
            content: "ä»€ä¹ˆæ˜¯Rustç¼–ç¨‹è¯­è¨€ï¼Ÿ".to_string(),
            metadata: None,
            name: None,
        },
    ];
    
    let start_time = Instant::now();
    let result = provider.generate_with_messages(&messages, &LlmOptions::default()).await;
    let duration = start_time.elapsed();
    
    match result {
        Ok(response) => {
            println!("âœ… DashScopeå¤šè½®å¯¹è¯æˆåŠŸ!");
            println!("ğŸ“ å“åº”å†…å®¹: {}", response);
            println!("â±ï¸ å“åº”æ—¶é—´: {:?}", duration);
        }
        Err(e) => {
            println!("âŒ DashScopeå¤šè½®å¯¹è¯å¤±è´¥: {}", e);
            return Err(format!("DashScopeå¤šè½®å¯¹è¯æµ‹è¯•å¤±è´¥: {}", e).into());
        }
    }
    
    Ok(())
}

async fn test_openai_compatible_api(api_key: &str, model: &str) -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•OpenAIå…¼å®¹APIå®ç°...");
    
    let provider = QwenProvider::new_with_api_type(
        api_key,
        model,
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
        QwenApiType::OpenAICompatible
    );
    
    // åŸºç¡€æ–‡æœ¬ç”Ÿæˆæµ‹è¯•
    let start_time = Instant::now();
    let result = provider.generate("Hello, please introduce yourself briefly.", &LlmOptions::default()).await;
    let duration = start_time.elapsed();
    
    match result {
        Ok(response) => {
            println!("âœ… OpenAIå…¼å®¹APIè°ƒç”¨æˆåŠŸ!");
            println!("ğŸ“ å“åº”å†…å®¹: {}", response);
            println!("â±ï¸ å“åº”æ—¶é—´: {:?}", duration);
        }
        Err(e) => {
            println!("âŒ OpenAIå…¼å®¹APIè°ƒç”¨å¤±è´¥: {}", e);
            println!("âš ï¸ æ³¨æ„: å¯èƒ½éœ€è¦æ·»åŠ enable_thinkingå‚æ•°");
            // ä¸ä½œä¸ºé”™è¯¯å¤„ç†ï¼Œå› ä¸ºå¯èƒ½éœ€è¦ç‰¹æ®Šå‚æ•°
        }
    }
    
    // åµŒå…¥å‘é‡æµ‹è¯•
    let start_time = Instant::now();
    let result = provider.get_embedding("è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚").await;
    let duration = start_time.elapsed();
    
    match result {
        Ok(embedding) => {
            println!("âœ… åµŒå…¥å‘é‡ç”ŸæˆæˆåŠŸ!");
            println!("ğŸ“Š å‘é‡ç»´åº¦: {}", embedding.len());
            println!("â±ï¸ ç”Ÿæˆæ—¶é—´: {:?}", duration);
            println!("ğŸ”¢ å‘é‡å‰5ä¸ªå€¼: {:?}", &embedding[..5.min(embedding.len())]);
        }
        Err(e) => {
            println!("âŒ åµŒå…¥å‘é‡ç”Ÿæˆå¤±è´¥: {}", e);
            println!("âš ï¸ æ³¨æ„: åµŒå…¥æ¨¡å‹å¯èƒ½ä¸æ”¯æŒæˆ–éœ€è¦ä¸åŒé…ç½®");
        }
    }
    
    // æµå¼å“åº”æµ‹è¯•
    println!("ğŸ§ª æµ‹è¯•æµå¼å“åº”...");
    let start_time = Instant::now();
    let stream_result = provider.generate_stream(
        "è¯·å†™ä¸€é¦–å…³äºäººå·¥æ™ºèƒ½çš„çŸ­è¯—ã€‚",
        &LlmOptions::default()
    ).await;
    
    match stream_result {
        Ok(mut stream) => {
            println!("âœ… æµå¼å“åº”å¯åŠ¨æˆåŠŸ!");
            
            use futures::StreamExt;
            let mut full_response = String::new();
            let mut chunk_count = 0;
            
            while let Some(chunk) = stream.next().await {
                match chunk {
                    Ok(text) => {
                        print!("{}", text);
                        full_response.push_str(&text);
                        chunk_count += 1;
                    }
                    Err(e) => {
                        println!("\nâŒ æµå¼å“åº”é”™è¯¯: {}", e);
                        break;
                    }
                }
            }
            
            let duration = start_time.elapsed();
            println!("\nâœ… æµå¼å“åº”å®Œæˆ!");
            println!("ğŸ“Š æ•°æ®å—æ•°é‡: {}", chunk_count);
            println!("â±ï¸ æ€»è€—æ—¶: {:?}", duration);
            println!("ğŸ“ å®Œæ•´å“åº”é•¿åº¦: {}", full_response.len());
        }
        Err(e) => {
            println!("âŒ æµå¼å“åº”å¯åŠ¨å¤±è´¥: {}", e);
            println!("âš ï¸ æ³¨æ„: æµå¼å“åº”å¯èƒ½éœ€è¦ç‰¹æ®Šé…ç½®");
        }
    }
    
    Ok(())
}

/// æµ‹è¯•ä¸åŒçš„LlmOptionsé…ç½®
async fn test_llm_options(provider: &QwenProvider) -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•ä¸åŒçš„LlmOptionsé…ç½®...");
    
    // æµ‹è¯•æ¸©åº¦å‚æ•°
    let mut options = LlmOptions::default();
    options.temperature = Some(0.1);
    options.max_tokens = Some(100);
    
    let result = provider.generate("è¯·ç®€å•å›ç­”ï¼šä»€ä¹ˆæ˜¯AIï¼Ÿ", &options).await;
    
    match result {
        Ok(response) => {
            println!("âœ… è‡ªå®šä¹‰å‚æ•°æµ‹è¯•æˆåŠŸ!");
            println!("ğŸ“ å“åº”å†…å®¹: {}", response);
        }
        Err(e) => {
            println!("âŒ è‡ªå®šä¹‰å‚æ•°æµ‹è¯•å¤±è´¥: {}", e);
        }
    }
    
    Ok(())
}

/// æ€§èƒ½åŸºå‡†æµ‹è¯•
async fn performance_benchmark(provider: &QwenProvider) -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æ€§èƒ½åŸºå‡†æµ‹è¯•...");
    
    let test_prompts = vec![
        "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
        "è§£é‡Šæ·±åº¦å­¦ä¹ çš„æ¦‚å¿µã€‚",
        "äººå·¥æ™ºèƒ½çš„åº”ç”¨é¢†åŸŸæœ‰å“ªäº›ï¼Ÿ",
    ];
    
    let mut total_time = std::time::Duration::new(0, 0);
    let mut success_count = 0;
    
    for (i, prompt) in test_prompts.iter().enumerate() {
        println!("ğŸ“ æµ‹è¯•æç¤º {}: {}", i + 1, prompt);
        
        let start_time = Instant::now();
        let result = provider.generate(prompt, &LlmOptions::default()).await;
        let duration = start_time.elapsed();
        
        match result {
            Ok(response) => {
                success_count += 1;
                total_time += duration;
                println!("âœ… æˆåŠŸ - è€—æ—¶: {:?}, å“åº”é•¿åº¦: {}", duration, response.len());
            }
            Err(e) => {
                println!("âŒ å¤±è´¥: {}", e);
            }
        }
        
        // é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        tokio::time::sleep(std::time::Duration::from_millis(500)).await;
    }
    
    let avg_time = if success_count > 0 {
        total_time / success_count
    } else {
        std::time::Duration::new(0, 0)
    };
    let success_rate = (success_count as f64 / test_prompts.len() as f64) * 100.0;
    
    println!("\nğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ:");
    println!("- æ€»æµ‹è¯•æ•°: {}", test_prompts.len());
    println!("- æˆåŠŸæ•°: {}", success_count);
    println!("- æˆåŠŸç‡: {:.1}%", success_rate);
    println!("- å¹³å‡å“åº”æ—¶é—´: {:?}", avg_time);
    println!("- æ€»è€—æ—¶: {:?}", total_time);
    
    Ok(())
}
