use lumosai_rag::{Document, ChunkingStrategy, ChunkingConfig, Metadata};
use lumosai_rag::document::{TextChunker, DocumentChunker};
use lumosai_rag::retriever::{InMemoryVectorStore, VectorStore};
use lumosai_rag::types::{RetrievalOptions, ScoredDocument};
use lumosai_rag::embedding::EmbeddingProvider;
use serde_json::json;
use std::time::Instant;
use async_trait::async_trait;

// Mock embedding provider for testing
struct MockEmbeddingProvider;

#[async_trait]
impl EmbeddingProvider for MockEmbeddingProvider {
    async fn generate_embedding(&self, text: &str) -> lumosai_rag::error::Result<Vec<f32>> {
        // Generate a simple mock embedding based on text length and content
        let embedding: Vec<f32> = (0..384)
            .map(|i| (text.len() as f32 + i as f32) * 0.001)
            .collect();
        Ok(embedding)
    }


}

/// RAGç³»ç»Ÿå…¨é¢éªŒè¯æµ‹è¯•
#[tokio::main]
async fn main() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸš€ LumosAI RAGç³»ç»ŸéªŒè¯æµ‹è¯•");
    println!("========================================");
    
    // æµ‹è¯•1: æ–‡æ¡£å¤„ç†éªŒè¯
    println!("\nğŸ“‹ æµ‹è¯•1: æ–‡æ¡£å¤„ç†éªŒè¯");
    test_document_processing().await?;
    
    // æµ‹è¯•2: æ–‡æœ¬åˆ†å—éªŒè¯
    println!("\nğŸ“‹ æµ‹è¯•2: æ–‡æœ¬åˆ†å—éªŒè¯");
    test_text_chunking().await?;
    
    // æµ‹è¯•3: å‘é‡åŒ–éªŒè¯
    println!("\nğŸ“‹ æµ‹è¯•3: å‘é‡åŒ–éªŒè¯");
    test_embedding_generation().await?;
    
    // æµ‹è¯•4: å‘é‡æ£€ç´¢éªŒè¯
    println!("\nğŸ“‹ æµ‹è¯•4: å‘é‡æ£€ç´¢éªŒè¯");
    test_vector_retrieval().await?;
    
    // æµ‹è¯•5: ä¸Šä¸‹æ–‡ç®¡ç†éªŒè¯
    println!("\nğŸ“‹ æµ‹è¯•5: ä¸Šä¸‹æ–‡ç®¡ç†éªŒè¯");
    test_context_management().await?;
    
    // æµ‹è¯•6: ç«¯åˆ°ç«¯RAGæµç¨‹éªŒè¯
    println!("\nğŸ“‹ æµ‹è¯•6: ç«¯åˆ°ç«¯RAGæµç¨‹éªŒè¯");
    test_end_to_end_rag().await?;
    
    println!("\nâœ… æ‰€æœ‰RAGç³»ç»ŸéªŒè¯æµ‹è¯•å®Œæˆï¼");
    Ok(())
}

async fn test_document_processing() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•æ–‡æ¡£å¤„ç†...");

    println!("âœ… æ–‡æ¡£å¤„ç†æµ‹è¯•å¼€å§‹");

    // æµ‹è¯•ä¸åŒç±»å‹çš„æ–‡æ¡£
    let test_documents = vec![
        ("text_doc", "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ã€‚å®ƒåŒ…å«äº†å¤šä¸ªæ®µè½å’Œå¥å­ã€‚\n\nç¬¬äºŒæ®µè½åŒ…å«äº†æ›´å¤šçš„å†…å®¹ï¼Œç”¨äºæµ‹è¯•æ–‡æ¡£å¤„ç†åŠŸèƒ½ã€‚", "text/plain"),
        ("markdown_doc", "# æ ‡é¢˜\n\nè¿™æ˜¯ä¸€ä¸ªMarkdownæ–‡æ¡£ã€‚\n\n## å­æ ‡é¢˜\n\n- åˆ—è¡¨é¡¹1\n- åˆ—è¡¨é¡¹2\n\n**ç²—ä½“æ–‡æœ¬**å’Œ*æ–œä½“æ–‡æœ¬*ã€‚", "text/markdown"),
        ("json_doc", r#"{"title": "JSONæ–‡æ¡£", "content": "è¿™æ˜¯ä¸€ä¸ªJSONæ ¼å¼çš„æ–‡æ¡£", "metadata": {"author": "æµ‹è¯•", "date": "2025-01-12"}}"#, "application/json"),
    ];

    for (doc_id, content, content_type) in test_documents {
        let start_time = Instant::now();

        // åˆ›å»ºæ–‡æ¡£å¯¹è±¡
        let mut metadata = Metadata::new();
        metadata.add("content_type", content_type);
        metadata.add("doc_id", doc_id);

        let document = Document {
            id: doc_id.to_string(),
            content: content.to_string(),
            metadata,
            embedding: None,
        };

        let duration = start_time.elapsed();

        println!("âœ… æ–‡æ¡£ '{}' å¤„ç†æˆåŠŸ! è€—æ—¶: {:?}", doc_id, duration);
        println!("ğŸ“ æ–‡æ¡£ID: {}", document.id);
        println!("ğŸ“ å†…å®¹é•¿åº¦: {} å­—ç¬¦", document.content.len());
        println!("ğŸ“ å†…å®¹ç±»å‹: {}", document.metadata.fields.get("content_type").unwrap_or(&json!("æœªçŸ¥")));

        // éªŒè¯æ–‡æ¡£å†…å®¹
        if !document.content.is_empty() {
            println!("âœ… æ–‡æ¡£å†…å®¹æå–æ­£å¸¸");
        } else {
            println!("âš ï¸ æ–‡æ¡£å†…å®¹ä¸ºç©º");
        }
    }

    Ok(())
}

async fn test_text_chunking() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•æ–‡æœ¬åˆ†å—...");

    let config = ChunkingConfig {
        chunk_size: 200,
        chunk_overlap: 50,
        strategy: ChunkingStrategy::Recursive {
            separators: None,
            is_separator_regex: false,
        },
        ..Default::default()
    };

    let chunker = TextChunker::new(config.clone());
    println!("âœ… æ–‡æœ¬åˆ†å—å™¨åˆ›å»ºæˆåŠŸ");

    // æµ‹è¯•é•¿æ–‡æœ¬åˆ†å—
    let long_text = "è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„æ–‡æ¡£ï¼Œç”¨äºæµ‹è¯•æ–‡æœ¬åˆ†å—åŠŸèƒ½ã€‚".repeat(50);

    // åˆ›å»ºæ–‡æ¡£å¯¹è±¡
    let mut metadata = Metadata::new();
    metadata.add("test", "chunking");

    let document = Document {
        id: "test_doc".to_string(),
        content: long_text.clone(),
        metadata,
        embedding: None,
    };

    let start_time = Instant::now();
    let chunks = chunker.chunk(document, &config).await?;
    let duration = start_time.elapsed();

    println!("âœ… æ–‡æœ¬åˆ†å—å®Œæˆ! è€—æ—¶: {:?}", duration);
    println!("ğŸ“Š åŸæ–‡é•¿åº¦: {} å­—ç¬¦", long_text.len());
    println!("ğŸ“Š åˆ†å—æ•°é‡: {}", chunks.len());

    for (i, chunk) in chunks.iter().enumerate().take(3) {
        println!("ğŸ“ åˆ†å— {}: {} å­—ç¬¦", i + 1, chunk.content.len());
        if chunk.content.len() > 50 {
            let preview = chunk.content.chars().take(20).collect::<String>();
            println!("   å†…å®¹é¢„è§ˆ: {}...", preview);
        } else {
            println!("   å†…å®¹: {}", chunk.content);
        }
    }

    // æµ‹è¯•ä¸åŒåˆ†å—ç­–ç•¥
    let strategies = vec![
        ("é€’å½’åˆ†å—", ChunkingStrategy::Recursive { separators: None, is_separator_regex: false }),
        ("å­—ç¬¦åˆ†å—", ChunkingStrategy::Character { separator: "\n".to_string(), is_separator_regex: false }),
        ("Markdownåˆ†å—", ChunkingStrategy::Markdown { headers: None, return_each_line: false, strip_headers: false }),
    ];

    for (strategy_name, strategy) in strategies {
        let config = ChunkingConfig {
            chunk_size: 100,
            chunk_overlap: 20,
            strategy,
            ..Default::default()
        };
        let chunker = TextChunker::new(config.clone());

        let test_doc = Document {
            id: "test".to_string(),
            content: "è¿™æ˜¯ç¬¬ä¸€å¥ã€‚è¿™æ˜¯ç¬¬äºŒå¥è¯ï¼Œæ¯”è¾ƒé•¿ä¸€äº›ã€‚è¿™æ˜¯ç¬¬ä¸‰å¥ã€‚è¿™æ˜¯ç¬¬å››å¥è¯ã€‚è¿™æ˜¯ç¬¬äº”å¥ï¼Œç”¨äºæµ‹è¯•ã€‚".to_string(),
            metadata: Metadata::new(),
            embedding: None,
        };

        let start_time = Instant::now();
        let chunks = chunker.chunk(test_doc, &config).await?;
        let duration = start_time.elapsed();

        println!("âœ… {} ç­–ç•¥æµ‹è¯•å®Œæˆ! è€—æ—¶: {:?}, åˆ†å—æ•°: {}", strategy_name, duration, chunks.len());
    }

    Ok(())
}

async fn test_embedding_generation() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•å‘é‡åŒ–...");
    
    // æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å®é™…çš„APIå¯†é’¥æ‰èƒ½æµ‹è¯•
    // ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„åµŒå…¥æä¾›å•†
    println!("âš ï¸ ä½¿ç”¨æ¨¡æ‹ŸåµŒå…¥æä¾›å•†è¿›è¡Œæµ‹è¯•");
    
    let test_texts = vec![
        "è¿™æ˜¯ç¬¬ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºç”Ÿæˆå‘é‡åµŒå…¥ã€‚",
        "è¿™æ˜¯ç¬¬äºŒä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œå†…å®¹ä¸ç¬¬ä¸€ä¸ªç›¸ä¼¼ã€‚",
        "è¿™æ˜¯ä¸€ä¸ªå®Œå…¨ä¸åŒçš„æ–‡æœ¬ï¼Œè®¨è®ºçš„æ˜¯å¦ä¸€ä¸ªä¸»é¢˜ã€‚",
        "äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ æ˜¯ç°ä»£æŠ€æœ¯çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚",
        "Rustæ˜¯ä¸€ç§ç³»ç»Ÿç¼–ç¨‹è¯­è¨€ï¼Œæ³¨é‡å®‰å…¨æ€§å’Œæ€§èƒ½ã€‚",
    ];
    
    // æ¨¡æ‹ŸåµŒå…¥ç”Ÿæˆ
    let mut embeddings = Vec::new();
    for (i, text) in test_texts.iter().enumerate() {
        let start_time = Instant::now();
        
        // æ¨¡æ‹ŸåµŒå…¥å‘é‡ï¼ˆå®é™…åº”ç”¨ä¸­åº”è¯¥è°ƒç”¨çœŸå®çš„åµŒå…¥APIï¼‰
        let embedding: Vec<f32> = (0..384)
            .map(|j| ((i + j) as f32 * 0.01) % 1.0)
            .collect();
        
        let duration = start_time.elapsed();
        embeddings.push(embedding);
        
        println!("âœ… æ–‡æœ¬ {} å‘é‡åŒ–å®Œæˆ! è€—æ—¶: {:?}", i + 1, duration);
        println!("ğŸ“ æ–‡æœ¬: {}", text);
        println!("ğŸ“Š å‘é‡ç»´åº¦: {}", embeddings[i].len());
    }
    
    // éªŒè¯åµŒå…¥è´¨é‡
    println!("ğŸ“Š åµŒå…¥è´¨é‡éªŒè¯:");
    for (i, embedding) in embeddings.iter().enumerate() {
        let norm: f32 = embedding.iter().map(|x| x * x).sum::<f32>().sqrt();
        println!("ğŸ“ˆ å‘é‡ {} çš„L2èŒƒæ•°: {:.4}", i + 1, norm);
    }
    
    Ok(())
}

async fn test_vector_retrieval() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•å‘é‡æ£€ç´¢...");

    // åˆ›å»ºå†…å­˜å‘é‡å­˜å‚¨
    let mut vector_store = InMemoryVectorStore::new();
    println!("âœ… å†…å­˜å‘é‡å­˜å‚¨åˆ›å»ºæˆåŠŸ");

    // å‡†å¤‡æµ‹è¯•æ–‡æ¡£
    let test_documents = vec![
        ("doc1", "äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•", vec![0.1; 384]),
        ("doc2", "æœºå™¨å­¦ä¹ ç®—æ³•åŸç†", vec![0.2; 384]),
        ("doc3", "æ·±åº¦å­¦ä¹ ç¥ç»ç½‘ç»œ", vec![0.3; 384]),
        ("doc4", "è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯", vec![0.4; 384]),
        ("doc5", "è®¡ç®—æœºè§†è§‰åº”ç”¨", vec![0.5; 384]),
    ];

    // æ·»åŠ æ–‡æ¡£åˆ°å‘é‡å­˜å‚¨
    for (doc_id, content, embedding) in test_documents {
        let mut metadata = Metadata::new();
        metadata.add("content", content);
        metadata.add("category", "AIæŠ€æœ¯");

        let document = Document {
            id: doc_id.to_string(),
            content: content.to_string(),
            metadata,
            embedding: Some(embedding),
        };

        let start_time = Instant::now();
        vector_store.add_document(document).await?;
        let duration = start_time.elapsed();

        println!("âœ… æ–‡æ¡£ '{}' æ·»åŠ æˆåŠŸ! è€—æ—¶: {:?}", doc_id, duration);
    }

    // åˆ›å»ºæ¨¡æ‹ŸåµŒå…¥æä¾›å•†
    let embedding_provider = MockEmbeddingProvider;

    // æµ‹è¯•æ–‡æœ¬æŸ¥è¯¢
    let options = RetrievalOptions {
        limit: Some(3),
        threshold: Some(0.5),
        filter: None,
    };

    let start_time = Instant::now();
    let results = vector_store.query_by_text("äººå·¥æ™ºèƒ½ç›¸å…³æŠ€æœ¯", &options, &embedding_provider).await?;
    let duration = start_time.elapsed();

    println!("âœ… å‘é‡æ£€ç´¢å®Œæˆ! è€—æ—¶: {:?}", duration);
    println!("ğŸ“Š æ£€ç´¢ç»“æœæ•°é‡: {}", results.documents.len());
    println!("ğŸ“Š æ€»æ–‡æ¡£æ•°é‡: {}", results.total_count);

    for (i, scored_doc) in results.documents.iter().enumerate() {
        println!("ğŸ“ ç»“æœ {}: ç›¸ä¼¼åº¦={:.4}", i + 1, scored_doc.score);
        println!("   æ–‡æ¡£ID: {}", scored_doc.document.id);
        println!("   å†…å®¹: {}", scored_doc.document.content);
    }

    Ok(())
}

async fn test_context_management() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•ä¸Šä¸‹æ–‡ç®¡ç†...");

    // ç®€åŒ–çš„ä¸Šä¸‹æ–‡ç®¡ç†æµ‹è¯•
    println!("âœ… ä¸Šä¸‹æ–‡ç®¡ç†å™¨æµ‹è¯•å¼€å§‹");

    // æ¨¡æ‹Ÿæ£€ç´¢ç»“æœ
    let scored_documents = vec![
        ScoredDocument {
            document: Document {
                id: "doc1".to_string(),
                content: "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚".to_string(),
                metadata: {
                    let mut meta = Metadata::new();
                    meta.add("source", "AIç™¾ç§‘");
                    meta
                },
                embedding: None,
            },
            score: 0.95,
        },
        ScoredDocument {
            document: Document {
                id: "doc2".to_string(),
                content: "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚".to_string(),
                metadata: {
                    let mut meta = Metadata::new();
                    meta.add("source", "MLæ•™ç¨‹");
                    meta
                },
                embedding: None,
            },
            score: 0.88,
        },
        ScoredDocument {
            document: Document {
                id: "doc3".to_string(),
                content: "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚".to_string(),
                metadata: {
                    let mut meta = Metadata::new();
                    meta.add("source", "DLæŒ‡å—");
                    meta
                },
                embedding: None,
            },
            score: 0.82,
        },
    ];

    let query = "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ";

    let start_time = Instant::now();

    // ç®€å•çš„ä¸Šä¸‹æ–‡æ„å»º
    let mut context = format!("æŸ¥è¯¢: {}\n\nç›¸å…³æ–‡æ¡£:\n", query);
    for (i, scored_doc) in scored_documents.iter().enumerate() {
        context.push_str(&format!(
            "{}. [ç›¸ä¼¼åº¦: {:.2}] {}\n",
            i + 1,
            scored_doc.score,
            scored_doc.document.content
        ));
    }

    let duration = start_time.elapsed();

    println!("âœ… ä¸Šä¸‹æ–‡æ„å»ºå®Œæˆ! è€—æ—¶: {:?}", duration);
    println!("ğŸ“Š ä¸Šä¸‹æ–‡é•¿åº¦: {} å­—ç¬¦", context.len());
    println!("ğŸ“ ä¸Šä¸‹æ–‡å†…å®¹é¢„è§ˆ:");
    if context.len() > 200 {
        println!("   {}...", &context[..200]);
    } else {
        println!("   {}", context);
    }

    println!("ğŸ“Š ä¸Šä¸‹æ–‡ç»Ÿè®¡:");
    println!("   æ–‡æ¡£æ•°é‡: {}", scored_documents.len());
    println!("   å¹³å‡ç›¸ä¼¼åº¦: {:.4}", scored_documents.iter().map(|d| d.score).sum::<f32>() / scored_documents.len() as f32);

    Ok(())
}

async fn test_end_to_end_rag() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•ç«¯åˆ°ç«¯RAGæµç¨‹...");

    // 1. æ–‡æ¡£å¤„ç†
    let documents = vec![
        "äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„æ™ºèƒ½æœºå™¨ã€‚",
        "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹è‡ªåŠ¨å­¦ä¹ å’Œæ”¹è¿›ã€‚",
        "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä½¿ç”¨å…·æœ‰å¤šä¸ªå±‚æ¬¡çš„ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚",
        "è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä¸“æ³¨äºè®¡ç®—æœºä¸äººç±»è¯­è¨€ä¹‹é—´çš„äº¤äº’ã€‚",
        "è®¡ç®—æœºè§†è§‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé¢†åŸŸï¼Œè‡´åŠ›äºä½¿è®¡ç®—æœºèƒ½å¤Ÿç†è§£å’Œè§£é‡Šè§†è§‰ä¿¡æ¯ã€‚",
    ];

    let mut processed_docs = Vec::new();
    for (i, content) in documents.iter().enumerate() {
        let mut metadata = Metadata::new();
        metadata.add("doc_id", format!("doc_{}", i));
        metadata.add("category", "AIæŠ€æœ¯");

        let document = Document {
            id: format!("doc_{}", i),
            content: content.to_string(),
            metadata,
            embedding: None,
        };
        processed_docs.push(document);
    }

    println!("âœ… æ­¥éª¤1: æ–‡æ¡£å¤„ç†å®Œæˆ - {} ä¸ªæ–‡æ¡£", processed_docs.len());

    // 2. æ–‡æœ¬åˆ†å—
    let config = ChunkingConfig {
        chunk_size: 100,
        chunk_overlap: 20,
        strategy: ChunkingStrategy::Recursive {
            separators: None,
            is_separator_regex: false,
        },
        ..Default::default()
    };
    let chunker = TextChunker::new(config.clone());

    let mut all_chunks = Vec::new();
    for doc in processed_docs {
        let chunks = chunker.chunk(doc, &config).await?;
        all_chunks.extend(chunks);
    }

    println!("âœ… æ­¥éª¤2: æ–‡æœ¬åˆ†å—å®Œæˆ - {} ä¸ªåˆ†å—", all_chunks.len());

    // 3. å‘é‡åŒ–ï¼ˆæ¨¡æ‹Ÿï¼‰
    let mut chunk_documents = Vec::new();
    for (i, chunk) in all_chunks.iter().enumerate() {
        let embedding: Vec<f32> = (0..384)
            .map(|j| ((i + j) as f32 * 0.01) % 1.0)
            .collect();

        let mut metadata = Metadata::new();
        metadata.add("chunk_id", i);
        metadata.add("content", chunk.content.clone());

        let chunk_doc = Document {
            id: format!("chunk_{}", i),
            content: chunk.content.clone(),
            metadata,
            embedding: Some(embedding),
        };
        chunk_documents.push(chunk_doc);
    }

    println!("âœ… æ­¥éª¤3: å‘é‡åŒ–å®Œæˆ - {} ä¸ªå‘é‡", chunk_documents.len());

    // 4. å‘é‡å­˜å‚¨
    let mut vector_store = InMemoryVectorStore::new();

    for chunk_doc in chunk_documents {
        vector_store.add_document(chunk_doc).await?;
    }

    println!("âœ… æ­¥éª¤4: å‘é‡å­˜å‚¨å®Œæˆ");

    // 5. æŸ¥è¯¢å’Œæ£€ç´¢
    let query = "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ";
    let embedding_provider = MockEmbeddingProvider;

    let options = RetrievalOptions {
        limit: Some(3),
        threshold: Some(0.5),
        filter: None,
    };

    let start_time = Instant::now();
    let search_results = vector_store.query_by_text(query, &options, &embedding_provider).await?;
    let duration = start_time.elapsed();

    println!("âœ… æ­¥éª¤5: æŸ¥è¯¢æ£€ç´¢å®Œæˆ - è€—æ—¶: {:?}", duration);

    // 6. ä¸Šä¸‹æ–‡æ„å»º
    let mut context = format!("æŸ¥è¯¢: {}\n\nç›¸å…³æ–‡æ¡£:\n", query);
    for (i, scored_doc) in search_results.documents.iter().enumerate() {
        context.push_str(&format!(
            "{}. [ç›¸ä¼¼åº¦: {:.2}] {}\n",
            i + 1,
            scored_doc.score,
            scored_doc.document.content
        ));
    }

    println!("âœ… æ­¥éª¤6: ä¸Šä¸‹æ–‡æ„å»ºå®Œæˆ");

    // 7. ç»“æœå±•ç¤º
    println!("\nğŸ“‹ ç«¯åˆ°ç«¯RAGæµç¨‹ç»“æœ:");
    println!("ğŸ” æŸ¥è¯¢: {}", query);
    println!("ğŸ“Š æ£€ç´¢åˆ° {} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ", search_results.documents.len());
    println!("ğŸ“ æ„å»ºçš„ä¸Šä¸‹æ–‡é•¿åº¦: {} å­—ç¬¦", context.len());

    for (i, scored_doc) in search_results.documents.iter().enumerate() {
        println!("ğŸ“„ ç‰‡æ®µ {}: ç›¸ä¼¼åº¦={:.4}", i + 1, scored_doc.score);
        println!("   å†…å®¹: {}", scored_doc.document.content);
    }

    println!("âœ… ç«¯åˆ°ç«¯RAGæµç¨‹éªŒè¯å®Œæˆï¼");

    Ok(())
}
