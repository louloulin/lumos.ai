use lumosai_core::llm::{QwenProvider, QwenApiType, Message, Role};
use lumosai_core::agent::{BasicAgent, AgentConfig};
use lumosai_core::agent::streaming::{IntoStreaming, AgentEvent};
use lumosai_core::agent::types::AgentGenerateOptions;
use lumosai_core::Agent;
use lumosai_rag::{Document, ChunkingStrategy, ChunkingConfig};
use lumosai_rag::document::chunker::{DocumentChunker, TextChunker};

use std::time::Instant;
use std::sync::Arc;
use tokio;
use futures::StreamExt;

/// çœŸå®ç»¼åˆé›†æˆéªŒè¯æµ‹è¯•
/// éªŒè¯LumosAIæ ¸å¿ƒç»„ä»¶çš„ç«¯åˆ°ç«¯é›†æˆåŠŸèƒ½
#[tokio::main]
async fn main() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸš€ LumosAI çœŸå®ç»¼åˆé›†æˆéªŒè¯æµ‹è¯•");
    println!("========================================");
    println!("ğŸ“‹ é…ç½®ä¿¡æ¯:");
    println!("  - æ¨¡å‹: qwen3-30b-a3b");
    println!("  - APIå¯†é’¥: sk-bc977c4e31e542f1a34159cb42478198");
    println!("  - åŸºç¡€URL: https://dashscope.aliyuncs.com/compatible-mode/v1");
    
    // 7.1 ç«¯åˆ°ç«¯RAG+æµå¼å¤„ç†é›†æˆæµ‹è¯•
    println!("\nğŸ“‹ 7.1 ç«¯åˆ°ç«¯RAG+æµå¼å¤„ç†é›†æˆæµ‹è¯•");
    test_rag_streaming_integration().await?;
    
    // 7.2 å¤šAgentåä½œæµ‹è¯•
    println!("\nğŸ“‹ 7.2 å¤šAgentåä½œæµ‹è¯•");
    test_multi_agent_collaboration().await?;
    
    // 7.3 å¤æ‚å·¥ä½œæµæµ‹è¯•
    println!("\nğŸ“‹ 7.3 å¤æ‚å·¥ä½œæµæµ‹è¯•");
    test_complex_workflow().await?;
    
    // 7.4 æ€§èƒ½å‹åŠ›æµ‹è¯•
    println!("\nğŸ“‹ 7.4 æ€§èƒ½å‹åŠ›æµ‹è¯•");
    test_performance_stress().await?;
    
    // 7.5 é”™è¯¯æ¢å¤å’Œé²æ£’æ€§æµ‹è¯•
    println!("\nğŸ“‹ 7.5 é”™è¯¯æ¢å¤å’Œé²æ£’æ€§æµ‹è¯•");
    test_error_recovery().await?;
    
    println!("\nâœ… ç»¼åˆé›†æˆéªŒè¯æµ‹è¯•å®Œæˆï¼");
    Ok(())
}

async fn test_rag_streaming_integration() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•RAG+æµå¼å¤„ç†é›†æˆ...");
    let start_time = Instant::now();
    
    // æµ‹è¯•ç”¨ä¾‹ 7.1.1: åˆ›å»ºçŸ¥è¯†åº“
    println!("    ğŸ“š åˆ›å»ºçŸ¥è¯†åº“");
    
    let documents = vec![
        Document {
            id: "tech_guide".to_string(),
            content: r#"
            # ç°ä»£è½¯ä»¶å¼€å‘æŠ€æœ¯æŒ‡å—
            
            ## ç¼–ç¨‹è¯­è¨€é€‰æ‹©
            - **Rust**: ç³»ç»Ÿç¼–ç¨‹è¯­è¨€ï¼Œæ³¨é‡å®‰å…¨æ€§å’Œæ€§èƒ½
            - **Python**: é€šç”¨ç¼–ç¨‹è¯­è¨€ï¼Œé€‚åˆAIå’Œæ•°æ®ç§‘å­¦
            - **JavaScript**: Webå¼€å‘çš„æ ¸å¿ƒè¯­è¨€
            - **Go**: äº‘åŸç”Ÿåº”ç”¨å¼€å‘çš„é¦–é€‰
            
            ## å¼€å‘æ¡†æ¶
            - **å‰ç«¯**: React, Vue.js, Angular
            - **åç«¯**: Express.js, Django, Spring Boot
            - **ç§»åŠ¨ç«¯**: React Native, Flutter
            
            ## æ•°æ®åº“æŠ€æœ¯
            - **å…³ç³»å‹**: PostgreSQL, MySQL
            - **NoSQL**: MongoDB, Redis
            - **å‘é‡æ•°æ®åº“**: Pinecone, Weaviate
            
            ## äº‘æœåŠ¡
            - **AWS**: äºšé©¬é€Šäº‘æœåŠ¡
            - **Azure**: å¾®è½¯äº‘å¹³å°
            - **GCP**: è°·æ­Œäº‘å¹³å°
            "#.to_string(),
            metadata: lumosai_rag::types::Metadata::new(),
            embedding: None,
        },
        Document {
            id: "ai_development".to_string(),
            content: r#"
            # AIå¼€å‘æœ€ä½³å®è·µ
            
            ## æœºå™¨å­¦ä¹ æµç¨‹
            1. **æ•°æ®æ”¶é›†**: è·å–é«˜è´¨é‡çš„è®­ç»ƒæ•°æ®
            2. **æ•°æ®é¢„å¤„ç†**: æ¸…æ´—å’Œæ ‡å‡†åŒ–æ•°æ®
            3. **æ¨¡å‹é€‰æ‹©**: é€‰æ‹©åˆé€‚çš„ç®—æ³•
            4. **è®­ç»ƒä¼˜åŒ–**: è°ƒæ•´è¶…å‚æ•°
            5. **æ¨¡å‹è¯„ä¼°**: éªŒè¯æ¨¡å‹æ€§èƒ½
            6. **éƒ¨ç½²ç›‘æ§**: ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
            
            ## æ·±åº¦å­¦ä¹ æ¡†æ¶
            - **PyTorch**: ç ”ç©¶å‹å¥½çš„æ·±åº¦å­¦ä¹ æ¡†æ¶
            - **TensorFlow**: å·¥ä¸šçº§æœºå™¨å­¦ä¹ å¹³å°
            - **JAX**: é«˜æ€§èƒ½æœºå™¨å­¦ä¹ ç ”ç©¶
            
            ## LLMåº”ç”¨å¼€å‘
            - **æç¤ºå·¥ç¨‹**: è®¾è®¡æœ‰æ•ˆçš„æç¤ºè¯
            - **RAGç³»ç»Ÿ**: æ£€ç´¢å¢å¼ºç”Ÿæˆ
            - **å¾®è°ƒæŠ€æœ¯**: æ¨¡å‹å®šåˆ¶åŒ–
            - **Agentæ¡†æ¶**: æ™ºèƒ½ä»£ç†å¼€å‘
            "#.to_string(),
            metadata: lumosai_rag::types::Metadata::new(),
            embedding: None,
        },
    ];
    
    // æµ‹è¯•ç”¨ä¾‹ 7.1.2: æ–‡æ¡£åˆ†å—å’Œå‘é‡åŒ–
    println!("    âœ‚ï¸ æ–‡æ¡£åˆ†å—å’Œå‘é‡åŒ–");
    
    let chunking_config = ChunkingConfig {
        chunk_size: 300,
        chunk_overlap: 50,
        min_chunk_size: Some(100),
        max_chunk_size: Some(500),
        strategy: ChunkingStrategy::Character {
            separator: "\n".to_string(),
            is_separator_regex: false,
        },
        preserve_metadata: true,
    };
    
    let chunker = TextChunker::new(chunking_config.clone());
    let mut all_chunks = Vec::new();
    
    for document in documents.iter() {
        let chunks = chunker.chunk(document.clone(), &chunking_config).await?;
        println!("      âœ“ æ–‡æ¡£ '{}' åˆ†å—: {} ä¸ªå—", document.id, chunks.len());
        all_chunks.extend(chunks);
    }
    
    println!("      âœ“ æ–‡æ¡£å¤„ç†å®Œæˆ: {} ä¸ªå—", all_chunks.len());
    
    // æµ‹è¯•ç”¨ä¾‹ 7.1.3: RAGæŸ¥è¯¢+æµå¼å“åº”
    println!("    ğŸ” RAGæŸ¥è¯¢+æµå¼å“åº”");
    
    let llm = QwenProvider::new_with_api_type(
        "sk-bc977c4e31e542f1a34159cb42478198",
        "qwen3-30b-a3b",
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
        QwenApiType::OpenAICompatible
    );
    
    let agent_config = AgentConfig {
        name: "RAGAgent".to_string(),
        instructions: "ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯ä¸“å®¶ï¼Œèƒ½å¤ŸåŸºäºæä¾›çš„çŸ¥è¯†åº“å›ç­”æŠ€æœ¯é—®é¢˜ã€‚è¯·æ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚".to_string(),
        memory_config: None,
        model_id: None,
        voice_config: None,
        telemetry: None,
        working_memory: None,
        enable_function_calling: Some(false),
        context: None,
        metadata: None,
        max_tool_calls: None,
        tool_timeout: None,
    };
    
    let agent = BasicAgent::new(agent_config, Arc::new(llm));
    let streaming_agent = agent.into_streaming();
    
    let queries = vec![
        "ä»€ä¹ˆæ˜¯Rustç¼–ç¨‹è¯­è¨€ï¼Ÿå®ƒæœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ",
        "å¦‚ä½•é€‰æ‹©åˆé€‚çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Ÿ",
        "RAGç³»ç»Ÿçš„å·¥ä½œåŸç†æ˜¯ä»€ä¹ˆï¼Ÿ",
    ];
    
    for (i, query) in queries.iter().enumerate() {
        println!("      ğŸ”„ æŸ¥è¯¢ {}: {}", i + 1, query);
        
        // æ¨¡æ‹Ÿæ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        let mut context = String::new();
        context.push_str("åŸºäºä»¥ä¸‹çŸ¥è¯†åº“ä¿¡æ¯å›ç­”é—®é¢˜ï¼š\n\n");

        // ç®€å•çš„å…³é”®è¯åŒ¹é…æ¥æ¨¡æ‹Ÿæ£€ç´¢
        let query_lower = query.to_lowercase();
        let mut relevant_chunks = Vec::new();

        for chunk in all_chunks.iter().take(3) {
            if chunk.content.to_lowercase().contains("rust") && query_lower.contains("rust") ||
               chunk.content.to_lowercase().contains("æ·±åº¦å­¦ä¹ ") && query_lower.contains("æ·±åº¦å­¦ä¹ ") ||
               chunk.content.to_lowercase().contains("rag") && query_lower.contains("rag") {
                relevant_chunks.push(&chunk.content);
            }
        }

        // å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œä½¿ç”¨å‰å‡ ä¸ªå—
        if relevant_chunks.is_empty() {
            relevant_chunks = all_chunks.iter().take(2).map(|c| &c.content).collect();
        }

        for (j, content) in relevant_chunks.iter().enumerate() {
            context.push_str(&format!("å‚è€ƒèµ„æ–™ {}:\n{}\n\n", j + 1, content));
        }
        context.push_str(&format!("é—®é¢˜: {}\n\nè¯·åŸºäºä¸Šè¿°èµ„æ–™æä¾›è¯¦ç»†å›ç­”ï¼š", query));
        
        let messages = vec![
            Message {
                role: Role::User,
                content: context,
                name: None,
                metadata: None,
            }
        ];
        
        let query_start = Instant::now();
        let options = AgentGenerateOptions::default();
        let mut stream = streaming_agent.execute_streaming(&messages, &options);
        
        let mut response_content = String::new();
        let mut chunk_count = 0;
        
        while let Some(event_result) = stream.next().await {
            match event_result {
                Ok(event) => {
                    match event {
                        AgentEvent::TextDelta { delta, .. } => {
                            chunk_count += 1;
                            response_content.push_str(&delta);
                        },
                        AgentEvent::GenerationComplete { .. } => {
                            break;
                        },
                        _ => {}
                    }
                },
                Err(e) => {
                    println!("        âŒ æµå¼å“åº”é”™è¯¯: {}", e);
                    break;
                }
            }
        }
        
        let query_duration = query_start.elapsed();
        
        println!("        âœ“ æŸ¥è¯¢å®Œæˆ (è€—æ—¶: {:?})", query_duration);
        println!("        ğŸ“Š å“åº”å—æ•°: {}", chunk_count);
        println!("        ğŸ“Š å“åº”é•¿åº¦: {} å­—ç¬¦", response_content.len());
        
        // éªŒè¯å“åº”è´¨é‡
        assert!(!response_content.trim().is_empty(), "RAGå“åº”ä¸èƒ½ä¸ºç©º");
        assert!(response_content.len() > 50, "RAGå“åº”åº”è¯¥è¶³å¤Ÿè¯¦ç»†");
        
        println!("        âœ“ æŸ¥è¯¢ {} éªŒè¯é€šè¿‡", i + 1);
    }
    
    let duration = start_time.elapsed();
    println!("  âœ… RAG+æµå¼å¤„ç†é›†æˆæµ‹è¯•å®Œæˆ! è€—æ—¶: {:?}", duration);
    
    Ok(())
}

async fn test_multi_agent_collaboration() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•å¤šAgentåä½œ...");
    let start_time = Instant::now();
    
    // æµ‹è¯•ç”¨ä¾‹ 7.2.1: åˆ›å»ºä¸“é—¨åŒ–Agent
    println!("    ğŸ¤– åˆ›å»ºä¸“é—¨åŒ–Agent");
    
    let llm = QwenProvider::new_with_api_type(
        "sk-bc977c4e31e542f1a34159cb42478198",
        "qwen3-30b-a3b",
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
        QwenApiType::OpenAICompatible
    );
    
    // æŠ€æœ¯åˆ†æå¸ˆAgent
    let tech_analyst_config = AgentConfig {
        name: "TechAnalyst".to_string(),
        instructions: "ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯åˆ†æå¸ˆï¼Œä¸“é—¨åˆ†ææŠ€æœ¯æ–¹æ¡ˆçš„å¯è¡Œæ€§ã€ä¼˜ç¼ºç‚¹å’Œå®æ–½å»ºè®®ã€‚".to_string(),
        memory_config: None,
        model_id: None,
        voice_config: None,
        telemetry: None,
        working_memory: None,
        enable_function_calling: Some(false),
        context: None,
        metadata: None,
        max_tool_calls: None,
        tool_timeout: None,
    };
    
    // é¡¹ç›®ç»ç†Agent
    let project_manager_config = AgentConfig {
        name: "ProjectManager".to_string(),
        instructions: "ä½ æ˜¯ä¸€ä¸ªé¡¹ç›®ç»ç†ï¼Œä¸“é—¨åˆ¶å®šé¡¹ç›®è®¡åˆ’ã€æ—¶é—´å®‰æ’å’Œèµ„æºåˆ†é…ã€‚".to_string(),
        memory_config: None,
        model_id: None,
        voice_config: None,
        telemetry: None,
        working_memory: None,
        enable_function_calling: Some(false),
        context: None,
        metadata: None,
        max_tool_calls: None,
        tool_timeout: None,
    };
    
    let tech_analyst = BasicAgent::new(tech_analyst_config, Arc::new(llm));

    let llm2 = QwenProvider::new_with_api_type(
        "sk-bc977c4e31e542f1a34159cb42478198",
        "qwen3-30b-a3b",
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
        QwenApiType::OpenAICompatible
    );
    let project_manager = BasicAgent::new(project_manager_config, Arc::new(llm2));
    
    println!("      âœ“ æŠ€æœ¯åˆ†æå¸ˆAgentåˆ›å»ºæˆåŠŸ");
    println!("      âœ“ é¡¹ç›®ç»ç†Agentåˆ›å»ºæˆåŠŸ");
    
    // æµ‹è¯•ç”¨ä¾‹ 7.2.2: Agentåä½œå·¥ä½œæµ
    println!("    ğŸ”„ Agentåä½œå·¥ä½œæµ");
    
    let project_request = "æˆ‘ä»¬éœ€è¦å¼€å‘ä¸€ä¸ªåŸºäºAIçš„å®¢æˆ·æœåŠ¡ç³»ç»Ÿï¼Œè¦æ±‚æ”¯æŒå¤šè¯­è¨€ã€å®æ—¶å“åº”ã€çŸ¥è¯†åº“é›†æˆã€‚è¯·åˆ†ææŠ€æœ¯æ–¹æ¡ˆå¹¶åˆ¶å®šé¡¹ç›®è®¡åˆ’ã€‚";
    
    // ç¬¬ä¸€æ­¥ï¼šæŠ€æœ¯åˆ†æå¸ˆåˆ†æ
    println!("      ğŸ“‹ æ­¥éª¤1: æŠ€æœ¯åˆ†æå¸ˆåˆ†æ");
    let tech_messages = vec![
        Message {
            role: Role::User,
            content: format!("è¯·åˆ†æä»¥ä¸‹é¡¹ç›®çš„æŠ€æœ¯æ–¹æ¡ˆï¼š\n\n{}\n\nè¯·æä¾›æŠ€æœ¯æ¶æ„å»ºè®®ã€æŠ€æœ¯æ ˆé€‰æ‹©å’Œå®æ–½éš¾ç‚¹åˆ†æã€‚", project_request),
            name: None,
            metadata: None,
        }
    ];
    
    let tech_analysis_start = Instant::now();
    let tech_response = tech_analyst.generate(&tech_messages, &Default::default()).await?;
    let tech_analysis_duration = tech_analysis_start.elapsed();
    
    println!("        âœ“ æŠ€æœ¯åˆ†æå®Œæˆ (è€—æ—¶: {:?})", tech_analysis_duration);
    println!("        ğŸ“Š åˆ†ææŠ¥å‘Šé•¿åº¦: {} å­—ç¬¦", tech_response.response.len());
    
    // ç¬¬äºŒæ­¥ï¼šé¡¹ç›®ç»ç†åˆ¶å®šè®¡åˆ’
    println!("      ğŸ“… æ­¥éª¤2: é¡¹ç›®ç»ç†åˆ¶å®šè®¡åˆ’");
    let pm_messages = vec![
        Message {
            role: Role::User,
            content: format!(
                "åŸºäºä»¥ä¸‹æŠ€æœ¯åˆ†ææŠ¥å‘Šï¼Œè¯·åˆ¶å®šè¯¦ç»†çš„é¡¹ç›®è®¡åˆ’ï¼š\n\nåŸå§‹éœ€æ±‚ï¼š\n{}\n\næŠ€æœ¯åˆ†ææŠ¥å‘Šï¼š\n{}\n\nè¯·æä¾›é¡¹ç›®æ—¶é—´çº¿ã€é‡Œç¨‹ç¢‘ã€èµ„æºéœ€æ±‚å’Œé£é™©è¯„ä¼°ã€‚",
                project_request,
                tech_response.response
            ),
            name: None,
            metadata: None,
        }
    ];
    
    let pm_planning_start = Instant::now();
    let pm_response = project_manager.generate(&pm_messages, &Default::default()).await?;
    let pm_planning_duration = pm_planning_start.elapsed();
    
    println!("        âœ“ é¡¹ç›®è®¡åˆ’å®Œæˆ (è€—æ—¶: {:?})", pm_planning_duration);
    println!("        ğŸ“Š é¡¹ç›®è®¡åˆ’é•¿åº¦: {} å­—ç¬¦", pm_response.response.len());
    
    // éªŒè¯åä½œç»“æœ
    assert!(!tech_response.response.trim().is_empty(), "æŠ€æœ¯åˆ†ææŠ¥å‘Šä¸èƒ½ä¸ºç©º");
    assert!(!pm_response.response.trim().is_empty(), "é¡¹ç›®è®¡åˆ’ä¸èƒ½ä¸ºç©º");
    assert!(tech_response.response.len() > 200, "æŠ€æœ¯åˆ†æåº”è¯¥è¶³å¤Ÿè¯¦ç»†");
    assert!(pm_response.response.len() > 200, "é¡¹ç›®è®¡åˆ’åº”è¯¥è¶³å¤Ÿè¯¦ç»†");
    
    println!("      âœ“ å¤šAgentåä½œéªŒè¯é€šè¿‡");
    
    let duration = start_time.elapsed();
    println!("  âœ… å¤šAgentåä½œæµ‹è¯•å®Œæˆ! è€—æ—¶: {:?}", duration);

    Ok(())
}

async fn test_complex_workflow() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•å¤æ‚å·¥ä½œæµ...");
    let start_time = Instant::now();

    // æµ‹è¯•ç”¨ä¾‹ 7.3.1: å¤šæ­¥éª¤å·¥ä½œæµ
    println!("    ğŸ”„ å¤šæ­¥éª¤å·¥ä½œæµ");

    let llm = QwenProvider::new_with_api_type(
        "sk-bc977c4e31e542f1a34159cb42478198",
        "qwen3-30b-a3b",
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
        QwenApiType::OpenAICompatible
    );

    let workflow_agent_config = AgentConfig {
        name: "WorkflowAgent".to_string(),
        instructions: "ä½ æ˜¯ä¸€ä¸ªå·¥ä½œæµå¤„ç†ä¸“å®¶ï¼Œèƒ½å¤Ÿæ‰§è¡Œå¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡ã€‚".to_string(),
        memory_config: None,
        model_id: None,
        voice_config: None,
        telemetry: None,
        working_memory: None,
        enable_function_calling: Some(false),
        context: None,
        metadata: None,
        max_tool_calls: None,
        tool_timeout: None,
    };

    let workflow_agent = BasicAgent::new(workflow_agent_config, Arc::new(llm));

    // å®šä¹‰å¤æ‚å·¥ä½œæµæ­¥éª¤
    let workflow_steps = vec![
        ("éœ€æ±‚åˆ†æ", "åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œæå–å…³é”®ä¿¡æ¯å’Œçº¦æŸæ¡ä»¶"),
        ("æ–¹æ¡ˆè®¾è®¡", "åŸºäºéœ€æ±‚åˆ†æç»“æœï¼Œè®¾è®¡æŠ€æœ¯æ–¹æ¡ˆ"),
        ("é£é™©è¯„ä¼°", "è¯„ä¼°æ–¹æ¡ˆçš„æŠ€æœ¯é£é™©å’Œå®æ–½éš¾åº¦"),
        ("å®æ–½è®¡åˆ’", "åˆ¶å®šè¯¦ç»†çš„å®æ–½è®¡åˆ’å’Œæ—¶é—´å®‰æ’"),
        ("è´¨é‡ä¿è¯", "å®šä¹‰è´¨é‡æ ‡å‡†å’ŒéªŒæ”¶æ ‡å‡†"),
    ];

    let initial_request = "å¼€å‘ä¸€ä¸ªä¼ä¸šçº§çš„æ™ºèƒ½æ–‡æ¡£ç®¡ç†ç³»ç»Ÿï¼Œéœ€è¦æ”¯æŒOCRè¯†åˆ«ã€è‡ªåŠ¨åˆ†ç±»ã€æ™ºèƒ½æœç´¢ã€æƒé™ç®¡ç†å’ŒAPIæ¥å£ã€‚";
    let mut workflow_context = initial_request.to_string();

    for (i, (step_name, step_description)) in workflow_steps.iter().enumerate() {
        println!("      ğŸ“‹ æ­¥éª¤ {}: {}", i + 1, step_name);

        let step_prompt = format!(
            "å½“å‰å·¥ä½œæµæ­¥éª¤: {}\nä»»åŠ¡æè¿°: {}\n\nä¸Šä¸‹æ–‡ä¿¡æ¯:\n{}\n\nè¯·æ‰§è¡Œå½“å‰æ­¥éª¤å¹¶æä¾›è¯¦ç»†ç»“æœï¼š",
            step_name, step_description, workflow_context
        );

        let messages = vec![
            Message {
                role: Role::User,
                content: step_prompt,
                name: None,
                metadata: None,
            }
        ];

        let step_start = Instant::now();
        let step_response = workflow_agent.generate(&messages, &Default::default()).await?;
        let step_duration = step_start.elapsed();

        // æ›´æ–°å·¥ä½œæµä¸Šä¸‹æ–‡
        workflow_context.push_str(&format!("\n\n=== {} ===\n{}", step_name, step_response.response));

        println!("        âœ“ {} å®Œæˆ (è€—æ—¶: {:?})", step_name, step_duration);
        println!("        ğŸ“Š è¾“å‡ºé•¿åº¦: {} å­—ç¬¦", step_response.response.len());

        // éªŒè¯æ­¥éª¤ç»“æœ
        assert!(!step_response.response.trim().is_empty(), "å·¥ä½œæµæ­¥éª¤è¾“å‡ºä¸èƒ½ä¸ºç©º");
        assert!(step_response.response.len() > 100, "å·¥ä½œæµæ­¥éª¤è¾“å‡ºåº”è¯¥è¶³å¤Ÿè¯¦ç»†");
    }

    println!("      âœ“ å¤æ‚å·¥ä½œæµæ‰§è¡Œå®Œæˆ");
    println!("      ğŸ“Š æœ€ç»ˆä¸Šä¸‹æ–‡é•¿åº¦: {} å­—ç¬¦", workflow_context.len());

    let duration = start_time.elapsed();
    println!("  âœ… å¤æ‚å·¥ä½œæµæµ‹è¯•å®Œæˆ! è€—æ—¶: {:?}", duration);

    Ok(())
}

async fn test_performance_stress() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•æ€§èƒ½å‹åŠ›...");
    let start_time = Instant::now();

    // æµ‹è¯•ç”¨ä¾‹ 7.4.1: å¹¶å‘è¯·æ±‚æµ‹è¯•
    println!("    âš¡ å¹¶å‘è¯·æ±‚æµ‹è¯•");

    let llm = QwenProvider::new_with_api_type(
        "sk-bc977c4e31e542f1a34159cb42478198",
        "qwen3-30b-a3b",
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
        QwenApiType::OpenAICompatible
    );

    let stress_agent_config = AgentConfig {
        name: "StressTestAgent".to_string(),
        instructions: "ä½ æ˜¯ä¸€ä¸ªæµ‹è¯•åŠ©æ‰‹ï¼Œè¯·ç®€æ´åœ°å›ç­”é—®é¢˜ã€‚".to_string(),
        memory_config: None,
        model_id: None,
        voice_config: None,
        telemetry: None,
        working_memory: None,
        enable_function_calling: Some(false),
        context: None,
        metadata: None,
        max_tool_calls: None,
        tool_timeout: None,
    };

    let stress_agent = Arc::new(BasicAgent::new(stress_agent_config, Arc::new(llm)));

    // åˆ›å»ºå¤šä¸ªå¹¶å‘ä»»åŠ¡
    let concurrent_tasks = 3; // å‡å°‘å¹¶å‘æ•°ä»¥é¿å…APIé™åˆ¶
    let mut handles = Vec::new();

    for i in 0..concurrent_tasks {
        let agent = stress_agent.clone();
        let handle = tokio::spawn(async move {
            let messages = vec![
                Message {
                    role: Role::User,
                    content: format!("è¿™æ˜¯å¹¶å‘æµ‹è¯•è¯·æ±‚ {}ï¼Œè¯·ç®€å•å›å¤ç¡®è®¤æ”¶åˆ°ã€‚", i + 1),
                    name: None,
                    metadata: None,
                }
            ];

            let task_start = Instant::now();
            let response = agent.generate(&messages, &Default::default()).await;
            let task_duration = task_start.elapsed();

            (i + 1, response, task_duration)
        });
        handles.push(handle);
    }

    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    let mut successful_tasks = 0;
    let mut total_duration = std::time::Duration::new(0, 0);

    for handle in handles {
        match handle.await {
            Ok((task_id, response_result, task_duration)) => {
                match response_result {
                    Ok(_response) => {
                        successful_tasks += 1;
                        total_duration += task_duration;
                        println!("        âœ“ ä»»åŠ¡ {} å®Œæˆ (è€—æ—¶: {:?})", task_id, task_duration);
                    },
                    Err(e) => {
                        println!("        âŒ ä»»åŠ¡ {} å¤±è´¥: {}", task_id, e);
                    }
                }
            },
            Err(e) => {
                println!("        âŒ ä»»åŠ¡æ‰§è¡Œé”™è¯¯: {}", e);
            }
        }
    }

    let avg_duration = total_duration / successful_tasks.max(1) as u32;

    println!("      ğŸ“Š å¹¶å‘æµ‹è¯•ç»“æœ:");
    println!("        - æ€»ä»»åŠ¡æ•°: {}", concurrent_tasks);
    println!("        - æˆåŠŸä»»åŠ¡æ•°: {}", successful_tasks);
    println!("        - å¹³å‡å“åº”æ—¶é—´: {:?}", avg_duration);

    // éªŒè¯æ€§èƒ½æŒ‡æ ‡
    assert!(successful_tasks > 0, "è‡³å°‘åº”æœ‰ä¸€ä¸ªä»»åŠ¡æˆåŠŸ");

    let duration = start_time.elapsed();
    println!("  âœ… æ€§èƒ½å‹åŠ›æµ‹è¯•å®Œæˆ! è€—æ—¶: {:?}", duration);

    Ok(())
}

async fn test_error_recovery() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•é”™è¯¯æ¢å¤å’Œé²æ£’æ€§...");
    let start_time = Instant::now();

    // æµ‹è¯•ç”¨ä¾‹ 7.5.1: æ— æ•ˆè¾“å…¥å¤„ç†
    println!("    ğŸ›¡ï¸ æ— æ•ˆè¾“å…¥å¤„ç†");

    let llm = QwenProvider::new_with_api_type(
        "sk-bc977c4e31e542f1a34159cb42478198",
        "qwen3-30b-a3b",
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
        QwenApiType::OpenAICompatible
    );

    let robust_agent_config = AgentConfig {
        name: "RobustAgent".to_string(),
        instructions: "ä½ æ˜¯ä¸€ä¸ªé²æ£’çš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿå¤„ç†å„ç§è¾“å…¥æƒ…å†µã€‚".to_string(),
        memory_config: None,
        model_id: None,
        voice_config: None,
        telemetry: None,
        working_memory: None,
        enable_function_calling: Some(false),
        context: None,
        metadata: None,
        max_tool_calls: None,
        tool_timeout: None,
    };

    let robust_agent = BasicAgent::new(robust_agent_config, Arc::new(llm));

    // æµ‹è¯•å„ç§è¾¹ç•Œæƒ…å†µ
    let test_cases = vec![
        ("ç©ºæ¶ˆæ¯", ""),
        ("æçŸ­æ¶ˆæ¯", "Hi"),
        ("é‡å¤å­—ç¬¦", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa"),
        ("ç‰¹æ®Šå­—ç¬¦", "!@#$%^&*()_+{}|:<>?[]\\;'\",./ "),
        ("æ··åˆè¯­è¨€", "Hello ä½ å¥½ ã“ã‚“ã«ã¡ã¯ ì•ˆë…•í•˜ì„¸ìš”"),
    ];

    for (test_name, test_input) in test_cases {
        println!("      ğŸ” æµ‹è¯•: {}", test_name);

        let messages = vec![
            Message {
                role: Role::User,
                content: test_input.to_string(),
                name: None,
                metadata: None,
            }
        ];

        let test_start = Instant::now();
        match robust_agent.generate(&messages, &Default::default()).await {
            Ok(response) => {
                let test_duration = test_start.elapsed();
                println!("        âœ“ å¤„ç†æˆåŠŸ (è€—æ—¶: {:?})", test_duration);
                println!("        ğŸ“Š å“åº”é•¿åº¦: {} å­—ç¬¦", response.response.len());

                // éªŒè¯å“åº”åˆç†æ€§
                if !test_input.is_empty() {
                    assert!(!response.response.trim().is_empty(), "éç©ºè¾“å…¥åº”è¯¥æœ‰å“åº”");
                }
            },
            Err(e) => {
                println!("        âš ï¸ å¤„ç†å¤±è´¥ï¼ˆå¯èƒ½æ˜¯é¢„æœŸçš„ï¼‰: {}", e);
            }
        }
    }

    println!("      âœ“ é”™è¯¯æ¢å¤æµ‹è¯•å®Œæˆ");

    let duration = start_time.elapsed();
    println!("  âœ… é”™è¯¯æ¢å¤å’Œé²æ£’æ€§æµ‹è¯•å®Œæˆ! è€—æ—¶: {:?}", duration);

    Ok(())
}
