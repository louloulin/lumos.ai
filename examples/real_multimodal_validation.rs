use lumosai_core::llm::{QwenProvider, QwenApiType, Message, Role};
use lumosai_core::agent::{BasicAgent, AgentConfig};
use lumosai_core::Agent;
use std::time::Instant;
use std::sync::Arc;
use tokio;
use serde_json::json;

/// çœŸå®å¤šæ¨¡æ€åŠŸèƒ½éªŒè¯æµ‹è¯•
/// éªŒè¯LumosAIçš„å¤šæ¨¡æ€å¤„ç†èƒ½åŠ›ï¼ˆå›¾åƒã€éŸ³é¢‘ç­‰ï¼‰
#[tokio::main]
async fn main() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ¨ LumosAI çœŸå®å¤šæ¨¡æ€åŠŸèƒ½éªŒè¯æµ‹è¯•");
    println!("========================================");
    println!("ğŸ“‹ é…ç½®ä¿¡æ¯:");
    println!("  - æ¨¡å‹: qwen3-30b-a3b");
    println!("  - APIå¯†é’¥: sk-bc977c4e31e542f1a34159cb42478198");
    println!("  - åŸºç¡€URL: https://dashscope.aliyuncs.com/compatible-mode/v1");
    
    // 9.1 å›¾åƒå¤„ç†èƒ½åŠ›éªŒè¯
    println!("\nğŸ“‹ 9.1 å›¾åƒå¤„ç†èƒ½åŠ›éªŒè¯");
    test_image_processing().await?;
    
    // 9.2 éŸ³é¢‘å¤„ç†èƒ½åŠ›éªŒè¯
    println!("\nğŸ“‹ 9.2 éŸ³é¢‘å¤„ç†èƒ½åŠ›éªŒè¯");
    test_audio_processing().await?;
    
    // 9.3 å¤šæ¨¡æ€å†…å®¹ç†è§£éªŒè¯
    println!("\nğŸ“‹ 9.3 å¤šæ¨¡æ€å†…å®¹ç†è§£éªŒè¯");
    test_multimodal_understanding().await?;
    
    // 9.4 å¤šæ¨¡æ€å†…å®¹ç”ŸæˆéªŒè¯
    println!("\nğŸ“‹ 9.4 å¤šæ¨¡æ€å†…å®¹ç”ŸæˆéªŒè¯");
    test_multimodal_generation().await?;
    
    // 9.5 è·¨æ¨¡æ€è½¬æ¢éªŒè¯
    println!("\nğŸ“‹ 9.5 è·¨æ¨¡æ€è½¬æ¢éªŒè¯");
    test_cross_modal_conversion().await?;
    
    println!("\nâœ… å¤šæ¨¡æ€åŠŸèƒ½éªŒè¯æµ‹è¯•å®Œæˆï¼");
    Ok(())
}

async fn test_image_processing() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•å›¾åƒå¤„ç†èƒ½åŠ›...");
    let start_time = Instant::now();
    
    // æµ‹è¯•ç”¨ä¾‹ 9.1.1: åˆ›å»ºå›¾åƒå¤„ç†Agent
    println!("    ğŸ–¼ï¸ æµ‹è¯•å›¾åƒå¤„ç†Agent");
    
    let llm = QwenProvider::new_with_api_type(
        "sk-bc977c4e31e542f1a34159cb42478198",
        "qwen3-30b-a3b",
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
        QwenApiType::OpenAICompatible
    );
    
    let image_agent_config = AgentConfig {
        name: "ImageAgent".to_string(),
        instructions: "ä½ æ˜¯ä¸€ä¸ªå›¾åƒå¤„ç†ä¸“å®¶ï¼Œèƒ½å¤Ÿåˆ†æã€æè¿°å’Œå¤„ç†å„ç§å›¾åƒå†…å®¹ã€‚".to_string(),
        memory_config: None,
        model_id: None,
        voice_config: None,
        telemetry: None,
        working_memory: None,
        enable_function_calling: Some(false),
        context: None,
        metadata: None,
        max_tool_calls: None,
        tool_timeout: None,
    };
    
    let image_agent = BasicAgent::new(image_agent_config, Arc::new(llm));
    
    println!("      âœ“ å›¾åƒå¤„ç†Agentåˆ›å»ºæˆåŠŸ");
    
    // æµ‹è¯•ç”¨ä¾‹ 9.1.2: å›¾åƒæè¿°å’Œåˆ†æ
    println!("    ğŸ” æµ‹è¯•å›¾åƒæè¿°å’Œåˆ†æ");
    
    // æ¨¡æ‹Ÿå›¾åƒå¤„ç†ä»»åŠ¡ï¼ˆç”±äºå½“å‰æ¨¡å‹é™åˆ¶ï¼Œæˆ‘ä»¬ä½¿ç”¨æ–‡æœ¬æè¿°æ¥æ¨¡æ‹Ÿï¼‰
    let image_tasks = vec![
        ("é£æ™¯ç…§ç‰‡", "ä¸€å¼ ç¾ä¸½çš„å±±æ°´é£æ™¯ç…§ç‰‡ï¼ŒåŒ…å«é›ªå±±ã€æ¹–æ³Šå’Œæ£®æ—"),
        ("äººç‰©è‚–åƒ", "ä¸€å¼ ä¸“ä¸šçš„å•†åŠ¡äººå£«è‚–åƒç…§ç‰‡ï¼ŒèƒŒæ™¯æ˜¯ç°ä»£åŠå…¬å®¤"),
        ("äº§å“å›¾ç‰‡", "ä¸€å¼ æ™ºèƒ½æ‰‹æœºçš„äº§å“å±•ç¤ºå›¾ç‰‡ï¼Œç™½è‰²èƒŒæ™¯ï¼Œçªå‡ºäº§å“ç‰¹å¾"),
        ("è‰ºæœ¯ä½œå“", "ä¸€å¹…æŠ½è±¡æ´¾æ²¹ç”»ä½œå“ï¼Œè‰²å½©ä¸°å¯Œï¼Œå……æ»¡åˆ›æ„"),
    ];
    
    for (image_type, image_description) in image_tasks {
        println!("      ğŸ”„ åˆ†æ{}: {}", image_type, image_description);
        
        let image_prompt = format!(
            "è¯·åˆ†æä»¥ä¸‹å›¾åƒå†…å®¹ï¼š\n\nå›¾åƒç±»å‹ï¼š{}\nå›¾åƒæè¿°ï¼š{}\n\nè¯·æä¾›è¯¦ç»†çš„å›¾åƒåˆ†æï¼ŒåŒ…æ‹¬ï¼š\n1. ä¸»è¦å†…å®¹å’Œå…ƒç´ \n2. è‰²å½©å’Œæ„å›¾åˆ†æ\n3. é£æ ¼å’ŒæŠ€æ³•è¯„ä»·\n4. å¯èƒ½çš„ç”¨é€”å’Œåº”ç”¨åœºæ™¯\n5. æ”¹è¿›å»ºè®®",
            image_type, image_description
        );
        
        let messages = vec![
            Message {
                role: Role::User,
                content: image_prompt,
                name: None,
                metadata: None,
            }
        ];
        
        let analysis_start = Instant::now();
        let response = image_agent.generate(&messages, &Default::default()).await?;
        let analysis_duration = analysis_start.elapsed();
        
        println!("        âœ“ {} åˆ†æå®Œæˆ (è€—æ—¶: {:?})", image_type, analysis_duration);
        println!("        ğŸ“Š åˆ†ææŠ¥å‘Šé•¿åº¦: {} å­—ç¬¦", response.response.len());
        
        // éªŒè¯å›¾åƒåˆ†æç»“æœ
        assert!(!response.response.trim().is_empty(), "å›¾åƒåˆ†æå“åº”ä¸èƒ½ä¸ºç©º");
        assert!(response.response.len() > 200, "å›¾åƒåˆ†æåº”è¯¥è¶³å¤Ÿè¯¦ç»†");
        
        // éªŒè¯æ˜¯å¦åŒ…å«å…³é”®åˆ†æè¦ç´ 
        let response_lower = response.response.to_lowercase();
        let analysis_elements = vec!["å†…å®¹", "è‰²å½©", "æ„å›¾", "é£æ ¼", "ç”¨é€”", "å»ºè®®"];
        let mut found_elements = 0;
        
        for element in analysis_elements {
            if response_lower.contains(element) {
                found_elements += 1;
            }
        }
        
        assert!(found_elements >= 3, "å›¾åƒåˆ†æåº”è¯¥åŒ…å«è‡³å°‘3ä¸ªå…³é”®è¦ç´ ");
        
        println!("        âœ“ {} éªŒè¯é€šè¿‡", image_type);
    }
    
    let duration = start_time.elapsed();
    println!("  âœ… å›¾åƒå¤„ç†èƒ½åŠ›æµ‹è¯•å®Œæˆ! è€—æ—¶: {:?}", duration);
    
    Ok(())
}

async fn test_audio_processing() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•éŸ³é¢‘å¤„ç†èƒ½åŠ›...");
    let start_time = Instant::now();
    
    // åˆ›å»ºéŸ³é¢‘å¤„ç†Agent
    let llm = QwenProvider::new_with_api_type(
        "sk-bc977c4e31e542f1a34159cb42478198",
        "qwen3-30b-a3b",
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
        QwenApiType::OpenAICompatible
    );
    
    let audio_agent_config = AgentConfig {
        name: "AudioAgent".to_string(),
        instructions: "ä½ æ˜¯ä¸€ä¸ªéŸ³é¢‘å¤„ç†ä¸“å®¶ï¼Œèƒ½å¤Ÿåˆ†æã€è½¬å½•å’Œå¤„ç†å„ç§éŸ³é¢‘å†…å®¹ã€‚".to_string(),
        memory_config: None,
        model_id: None,
        voice_config: None,
        telemetry: None,
        working_memory: None,
        enable_function_calling: Some(false),
        context: None,
        metadata: None,
        max_tool_calls: None,
        tool_timeout: None,
    };
    
    let audio_agent = BasicAgent::new(audio_agent_config, Arc::new(llm));
    
    // æµ‹è¯•ç”¨ä¾‹ 9.2.1: éŸ³é¢‘å†…å®¹åˆ†æ
    println!("    ğŸµ æµ‹è¯•éŸ³é¢‘å†…å®¹åˆ†æ");
    
    let audio_tasks = vec![
        ("ä¼šè®®å½•éŸ³", "ä¸€æ®µ30åˆ†é’Ÿçš„å•†åŠ¡ä¼šè®®å½•éŸ³ï¼ŒåŒ…å«å¤šäººè®¨è®ºé¡¹ç›®è¿›å±•"),
        ("éŸ³ä¹ä½œå“", "ä¸€é¦–å¤å…¸éŸ³ä¹ä½œå“ï¼Œé’¢ç´ç‹¬å¥ï¼Œæƒ…æ„Ÿä¸°å¯Œ"),
        ("æ’­å®¢èŠ‚ç›®", "ä¸€æœŸç§‘æŠ€æ’­å®¢èŠ‚ç›®ï¼Œä¸»æŒäººé‡‡è®¿AIä¸“å®¶"),
        ("è¯­éŸ³å¤‡å¿˜", "ä¸ªäººè¯­éŸ³å¤‡å¿˜å½•ï¼Œè®°å½•æ—¥å¸¸å·¥ä½œå®‰æ’å’Œæƒ³æ³•"),
    ];
    
    for (audio_type, audio_description) in audio_tasks {
        println!("      ğŸ”„ åˆ†æ{}: {}", audio_type, audio_description);
        
        let audio_prompt = format!(
            "è¯·åˆ†æä»¥ä¸‹éŸ³é¢‘å†…å®¹ï¼š\n\néŸ³é¢‘ç±»å‹ï¼š{}\néŸ³é¢‘æè¿°ï¼š{}\n\nè¯·æä¾›è¯¦ç»†çš„éŸ³é¢‘åˆ†æï¼ŒåŒ…æ‹¬ï¼š\n1. å†…å®¹æ‘˜è¦å’Œå…³é”®ä¿¡æ¯\n2. éŸ³è´¨å’ŒæŠ€æœ¯ç‰¹å¾\n3. è¯­éŸ³è¯†åˆ«å’Œè½¬å½•å»ºè®®\n4. åå¤„ç†å’Œä¼˜åŒ–æ–¹æ¡ˆ\n5. åº”ç”¨åœºæ™¯å’Œä»·å€¼è¯„ä¼°",
            audio_type, audio_description
        );
        
        let messages = vec![
            Message {
                role: Role::User,
                content: audio_prompt,
                name: None,
                metadata: None,
            }
        ];
        
        let analysis_start = Instant::now();
        let response = audio_agent.generate(&messages, &Default::default()).await?;
        let analysis_duration = analysis_start.elapsed();
        
        println!("        âœ“ {} åˆ†æå®Œæˆ (è€—æ—¶: {:?})", audio_type, analysis_duration);
        println!("        ğŸ“Š åˆ†ææŠ¥å‘Šé•¿åº¦: {} å­—ç¬¦", response.response.len());
        
        // éªŒè¯éŸ³é¢‘åˆ†æç»“æœ
        assert!(!response.response.trim().is_empty(), "éŸ³é¢‘åˆ†æå“åº”ä¸èƒ½ä¸ºç©º");
        assert!(response.response.len() > 200, "éŸ³é¢‘åˆ†æåº”è¯¥è¶³å¤Ÿè¯¦ç»†");
        
        // éªŒè¯æ˜¯å¦åŒ…å«å…³é”®åˆ†æè¦ç´ 
        let response_lower = response.response.to_lowercase();
        let analysis_elements = vec!["å†…å®¹", "éŸ³è´¨", "è½¬å½•", "å¤„ç†", "åº”ç”¨"];
        let mut found_elements = 0;
        
        for element in analysis_elements {
            if response_lower.contains(element) {
                found_elements += 1;
            }
        }
        
        assert!(found_elements >= 3, "éŸ³é¢‘åˆ†æåº”è¯¥åŒ…å«è‡³å°‘3ä¸ªå…³é”®è¦ç´ ");
        
        println!("        âœ“ {} éªŒè¯é€šè¿‡", audio_type);
    }
    
    let duration = start_time.elapsed();
    println!("  âœ… éŸ³é¢‘å¤„ç†èƒ½åŠ›æµ‹è¯•å®Œæˆ! è€—æ—¶: {:?}", duration);
    
    Ok(())
}

async fn test_multimodal_understanding() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•å¤šæ¨¡æ€å†…å®¹ç†è§£...");
    let start_time = Instant::now();
    
    // åˆ›å»ºå¤šæ¨¡æ€ç†è§£Agent
    let llm = QwenProvider::new_with_api_type(
        "sk-bc977c4e31e542f1a34159cb42478198",
        "qwen3-30b-a3b",
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
        QwenApiType::OpenAICompatible
    );
    
    let multimodal_agent_config = AgentConfig {
        name: "MultimodalAgent".to_string(),
        instructions: "ä½ æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€å†…å®¹ç†è§£ä¸“å®¶ï¼Œèƒ½å¤Ÿç»¼åˆåˆ†ææ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ç­‰å¤šç§æ¨¡æ€çš„å†…å®¹ã€‚".to_string(),
        memory_config: None,
        model_id: None,
        voice_config: None,
        telemetry: None,
        working_memory: None,
        enable_function_calling: Some(false),
        context: None,
        metadata: None,
        max_tool_calls: None,
        tool_timeout: None,
    };
    
    let multimodal_agent = BasicAgent::new(multimodal_agent_config, Arc::new(llm));
    
    // æµ‹è¯•ç”¨ä¾‹ 9.3.1: å¤šæ¨¡æ€å†…å®¹ç»¼åˆç†è§£
    println!("    ğŸ”— æµ‹è¯•å¤šæ¨¡æ€å†…å®¹ç»¼åˆç†è§£");
    
    let multimodal_content = json!({
        "scenario": "äº§å“å‘å¸ƒä¼š",
        "text_content": "æˆ‘ä»¬ä»Šå¤©å‘å¸ƒçš„æ–°æ¬¾æ™ºèƒ½æ‰‹æœºå…·æœ‰é©å‘½æ€§çš„AIæ‘„å½±åŠŸèƒ½ï¼Œæ”¯æŒå¤œæ™¯æ¨¡å¼å’Œäººåƒç¾åŒ–ã€‚",
        "image_content": "äº§å“å±•ç¤ºå›¾ç‰‡ï¼šä¸€æ¬¾é»‘è‰²æ™ºèƒ½æ‰‹æœºï¼Œå±å¹•æ˜¾ç¤ºç›¸æœºç•Œé¢ï¼ŒèƒŒæ™¯æ˜¯ä¸“ä¸šæ‘„å½±æ£š",
        "audio_content": "å‘å¸ƒä¼šç°åœºå½•éŸ³ï¼šCEOä»‹ç»äº§å“ç‰¹æ€§ï¼Œè§‚ä¼—çƒ­çƒˆæŒå£°ï¼ŒèƒŒæ™¯éŸ³ä¹è½»æŸ”",
        "video_content": "äº§å“æ¼”ç¤ºè§†é¢‘ï¼šå±•ç¤ºæ‰‹æœºæ‹ç…§åŠŸèƒ½ï¼Œä»ç™½å¤©åˆ°å¤œæ™šçš„æ‹æ‘„æ•ˆæœå¯¹æ¯”"
    });
    
    let multimodal_prompt = format!(
        "è¯·ç»¼åˆåˆ†æä»¥ä¸‹å¤šæ¨¡æ€å†…å®¹ï¼š\n{}\n\nè¯·æä¾›å…¨é¢çš„å¤šæ¨¡æ€åˆ†æï¼ŒåŒ…æ‹¬ï¼š\n1. å„æ¨¡æ€å†…å®¹çš„ä¸€è‡´æ€§åˆ†æ\n2. ä¿¡æ¯äº’è¡¥å’Œå¢å¼ºæ•ˆæœ\n3. æ•´ä½“ä¼ è¾¾çš„æ ¸å¿ƒä¿¡æ¯\n4. å—ä¼—ä½“éªŒå’Œæƒ…æ„Ÿå½±å“\n5. å¤šæ¨¡æ€ååŒçš„ä¼˜åŒ–å»ºè®®",
        serde_json::to_string_pretty(&multimodal_content)?
    );
    
    let messages = vec![
        Message {
            role: Role::User,
            content: multimodal_prompt,
            name: None,
            metadata: None,
        }
    ];
    
    let understanding_start = Instant::now();
    let response = multimodal_agent.generate(&messages, &Default::default()).await?;
    let understanding_duration = understanding_start.elapsed();
    
    println!("      âœ“ å¤šæ¨¡æ€ç†è§£å®Œæˆ (è€—æ—¶: {:?})", understanding_duration);
    println!("      ğŸ“Š ç†è§£æŠ¥å‘Šé•¿åº¦: {} å­—ç¬¦", response.response.len());
    
    // éªŒè¯å¤šæ¨¡æ€ç†è§£ç»“æœ
    assert!(!response.response.trim().is_empty(), "å¤šæ¨¡æ€ç†è§£å“åº”ä¸èƒ½ä¸ºç©º");
    assert!(response.response.len() > 400, "å¤šæ¨¡æ€ç†è§£åº”è¯¥éå¸¸è¯¦ç»†");
    
    // éªŒè¯æ˜¯å¦åŒ…å«å…³é”®ç†è§£è¦ç´ 
    let response_lower = response.response.to_lowercase();
    let understanding_elements = vec!["ä¸€è‡´æ€§", "äº’è¡¥", "æ ¸å¿ƒä¿¡æ¯", "ä½“éªŒ", "ä¼˜åŒ–"];
    let mut found_elements = 0;
    
    for element in understanding_elements {
        if response_lower.contains(element) {
            found_elements += 1;
        }
    }
    
    assert!(found_elements >= 3, "å¤šæ¨¡æ€ç†è§£åº”è¯¥åŒ…å«è‡³å°‘3ä¸ªå…³é”®è¦ç´ ");
    
    println!("      âœ“ å¤šæ¨¡æ€ç†è§£éªŒè¯é€šè¿‡");
    
    let duration = start_time.elapsed();
    println!("  âœ… å¤šæ¨¡æ€å†…å®¹ç†è§£æµ‹è¯•å®Œæˆ! è€—æ—¶: {:?}", duration);

    Ok(())
}

async fn test_multimodal_generation() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•å¤šæ¨¡æ€å†…å®¹ç”Ÿæˆ...");
    let start_time = Instant::now();

    // åˆ›å»ºå¤šæ¨¡æ€ç”ŸæˆAgent
    let llm = QwenProvider::new_with_api_type(
        "sk-bc977c4e31e542f1a34159cb42478198",
        "qwen3-30b-a3b",
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
        QwenApiType::OpenAICompatible
    );

    let generation_agent_config = AgentConfig {
        name: "GenerationAgent".to_string(),
        instructions: "ä½ æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€å†…å®¹ç”Ÿæˆä¸“å®¶ï¼Œèƒ½å¤Ÿæ ¹æ®éœ€æ±‚ç”Ÿæˆæ–‡æœ¬ã€å›¾åƒæè¿°ã€éŸ³é¢‘è„šæœ¬ç­‰å¤šç§æ¨¡æ€çš„å†…å®¹ã€‚".to_string(),
        memory_config: None,
        model_id: None,
        voice_config: None,
        telemetry: None,
        working_memory: None,
        enable_function_calling: Some(false),
        context: None,
        metadata: None,
        max_tool_calls: None,
        tool_timeout: None,
    };

    let generation_agent = BasicAgent::new(generation_agent_config, Arc::new(llm));

    // æµ‹è¯•ç”¨ä¾‹ 9.4.1: å¤šæ¨¡æ€å†…å®¹ç”Ÿæˆ
    println!("    ğŸ¨ æµ‹è¯•å¤šæ¨¡æ€å†…å®¹ç”Ÿæˆ");

    let generation_tasks = vec![
        ("è¥é”€æ´»åŠ¨", "ä¸ºæ–°äº§å“å‘å¸ƒè®¾è®¡ä¸€å¥—å®Œæ•´çš„è¥é”€å†…å®¹"),
        ("æ•™è‚²è¯¾ç¨‹", "ä¸ºåœ¨çº¿ç¼–ç¨‹è¯¾ç¨‹åˆ›å»ºå¤šåª’ä½“æ•™å­¦ææ–™"),
        ("å“ç‰Œå®£ä¼ ", "ä¸ºç§‘æŠ€å…¬å¸è®¾è®¡å“ç‰Œå½¢è±¡å®£ä¼ å†…å®¹"),
    ];

    for (task_type, task_description) in generation_tasks {
        println!("      ğŸ”„ ç”Ÿæˆ{}: {}", task_type, task_description);

        let generation_prompt = format!(
            "è¯·ä¸ºä»¥ä¸‹ä»»åŠ¡ç”Ÿæˆå®Œæ•´çš„å¤šæ¨¡æ€å†…å®¹æ–¹æ¡ˆï¼š\n\nä»»åŠ¡ç±»å‹ï¼š{}\nä»»åŠ¡æè¿°ï¼š{}\n\nè¯·æä¾›ï¼š\n1. æ–‡æœ¬å†…å®¹ï¼ˆæ ‡é¢˜ã€æ­£æ–‡ã€æ ‡è¯­ç­‰ï¼‰\n2. å›¾åƒè®¾è®¡æ–¹æ¡ˆï¼ˆæ„å›¾ã€è‰²å½©ã€é£æ ¼ç­‰ï¼‰\n3. éŸ³é¢‘å†…å®¹è§„åˆ’ï¼ˆé…éŸ³ã€éŸ³æ•ˆã€èƒŒæ™¯éŸ³ä¹ç­‰ï¼‰\n4. è§†é¢‘è„šæœ¬å¤§çº²\n5. å„æ¨¡æ€å†…å®¹çš„åè°ƒç»Ÿä¸€æ–¹æ¡ˆ",
            task_type, task_description
        );

        let messages = vec![
            Message {
                role: Role::User,
                content: generation_prompt,
                name: None,
                metadata: None,
            }
        ];

        let generation_start = Instant::now();
        let response = generation_agent.generate(&messages, &Default::default()).await?;
        let generation_duration = generation_start.elapsed();

        println!("        âœ“ {} ç”Ÿæˆå®Œæˆ (è€—æ—¶: {:?})", task_type, generation_duration);
        println!("        ğŸ“Š ç”Ÿæˆæ–¹æ¡ˆé•¿åº¦: {} å­—ç¬¦", response.response.len());

        // éªŒè¯å¤šæ¨¡æ€ç”Ÿæˆç»“æœ
        assert!(!response.response.trim().is_empty(), "å¤šæ¨¡æ€ç”Ÿæˆå“åº”ä¸èƒ½ä¸ºç©º");
        assert!(response.response.len() > 500, "å¤šæ¨¡æ€ç”Ÿæˆæ–¹æ¡ˆåº”è¯¥éå¸¸è¯¦ç»†");

        // éªŒè¯æ˜¯å¦åŒ…å«å„ç§æ¨¡æ€å†…å®¹
        let response_lower = response.response.to_lowercase();
        let modality_elements = vec!["æ–‡æœ¬", "å›¾åƒ", "éŸ³é¢‘", "è§†é¢‘", "åè°ƒ"];
        let mut found_elements = 0;

        for element in modality_elements {
            if response_lower.contains(element) {
                found_elements += 1;
            }
        }

        assert!(found_elements >= 4, "å¤šæ¨¡æ€ç”Ÿæˆåº”è¯¥åŒ…å«è‡³å°‘4ç§æ¨¡æ€å†…å®¹");

        println!("        âœ“ {} éªŒè¯é€šè¿‡", task_type);
    }

    let duration = start_time.elapsed();
    println!("  âœ… å¤šæ¨¡æ€å†…å®¹ç”Ÿæˆæµ‹è¯•å®Œæˆ! è€—æ—¶: {:?}", duration);

    Ok(())
}

async fn test_cross_modal_conversion() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•è·¨æ¨¡æ€è½¬æ¢...");
    let start_time = Instant::now();

    // åˆ›å»ºè·¨æ¨¡æ€è½¬æ¢Agent
    let llm = QwenProvider::new_with_api_type(
        "sk-bc977c4e31e542f1a34159cb42478198",
        "qwen3-30b-a3b",
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
        QwenApiType::OpenAICompatible
    );

    let conversion_agent_config = AgentConfig {
        name: "ConversionAgent".to_string(),
        instructions: "ä½ æ˜¯ä¸€ä¸ªè·¨æ¨¡æ€è½¬æ¢ä¸“å®¶ï¼Œèƒ½å¤Ÿåœ¨ä¸åŒæ¨¡æ€ä¹‹é—´è¿›è¡Œå†…å®¹è½¬æ¢å’Œé€‚é…ã€‚".to_string(),
        memory_config: None,
        model_id: None,
        voice_config: None,
        telemetry: None,
        working_memory: None,
        enable_function_calling: Some(false),
        context: None,
        metadata: None,
        max_tool_calls: None,
        tool_timeout: None,
    };

    let conversion_agent = BasicAgent::new(conversion_agent_config, Arc::new(llm));

    // æµ‹è¯•ç”¨ä¾‹ 9.5.1: è·¨æ¨¡æ€è½¬æ¢
    println!("    ğŸ”„ æµ‹è¯•è·¨æ¨¡æ€è½¬æ¢");

    let conversion_tasks = vec![
        ("æ–‡æœ¬è½¬å›¾åƒ", "å°†ä¸€æ®µäº§å“æè¿°æ–‡æœ¬è½¬æ¢ä¸ºå›¾åƒè®¾è®¡æ–¹æ¡ˆ", "è¿™æ¬¾æ™ºèƒ½æ‰‹è¡¨å…·æœ‰åœ†å½¢è¡¨ç›˜ã€é‡‘å±è¡¨å¸¦ï¼Œæ”¯æŒå¥åº·ç›‘æµ‹å’Œè¿åŠ¨è¿½è¸ªåŠŸèƒ½"),
        ("å›¾åƒè½¬æ–‡æœ¬", "å°†å›¾åƒå†…å®¹è½¬æ¢ä¸ºè¯¦ç»†çš„æ–‡å­—æè¿°", "ä¸€å¼ å±•ç¤ºç°ä»£åŠå…¬å®¤çš„ç…§ç‰‡ï¼ŒåŒ…å«å¼€æ”¾å¼å·¥ä½œåŒºã€ç»¿æ¤è£…é¥°å’Œè‡ªç„¶å…‰ç…§æ˜"),
        ("éŸ³é¢‘è½¬æ–‡æœ¬", "å°†éŸ³é¢‘å†…å®¹è½¬æ¢ä¸ºæ–‡å­—è®°å½•", "ä¸€æ®µå®¢æˆ·æœåŠ¡ç”µè¯å½•éŸ³ï¼Œå®¢æˆ·å’¨è¯¢äº§å“é€€æ¢è´§æ”¿ç­–"),
        ("æ–‡æœ¬è½¬éŸ³é¢‘", "å°†æ–‡æœ¬å†…å®¹è½¬æ¢ä¸ºéŸ³é¢‘è„šæœ¬", "å…¬å¸å¹´åº¦æ€»ç»“æŠ¥å‘Šï¼Œéœ€è¦åˆ¶ä½œæˆæ’­å®¢èŠ‚ç›®"),
    ];

    for (conversion_type, conversion_description, source_content) in conversion_tasks {
        println!("      ğŸ”„ æ‰§è¡Œ{}: {}", conversion_type, conversion_description);

        let conversion_prompt = format!(
            "è¯·æ‰§è¡Œä»¥ä¸‹è·¨æ¨¡æ€è½¬æ¢ä»»åŠ¡ï¼š\n\nè½¬æ¢ç±»å‹ï¼š{}\nä»»åŠ¡æè¿°ï¼š{}\næºå†…å®¹ï¼š{}\n\nè¯·æä¾›ï¼š\n1. è½¬æ¢åçš„ç›®æ ‡å†…å®¹\n2. è½¬æ¢è¿‡ç¨‹ä¸­çš„å…³é”®è€ƒè™‘å› ç´ \n3. ä¿¡æ¯ä¿çœŸåº¦è¯„ä¼°\n4. ç›®æ ‡æ¨¡æ€çš„ä¼˜åŒ–å»ºè®®\n5. å¯èƒ½çš„è´¨é‡æŸå¤±å’Œè¡¥å¿æ–¹æ¡ˆ",
            conversion_type, conversion_description, source_content
        );

        let messages = vec![
            Message {
                role: Role::User,
                content: conversion_prompt,
                name: None,
                metadata: None,
            }
        ];

        let conversion_start = Instant::now();
        let response = conversion_agent.generate(&messages, &Default::default()).await?;
        let conversion_duration = conversion_start.elapsed();

        println!("        âœ“ {} è½¬æ¢å®Œæˆ (è€—æ—¶: {:?})", conversion_type, conversion_duration);
        println!("        ğŸ“Š è½¬æ¢ç»“æœé•¿åº¦: {} å­—ç¬¦", response.response.len());

        // éªŒè¯è·¨æ¨¡æ€è½¬æ¢ç»“æœ
        assert!(!response.response.trim().is_empty(), "è·¨æ¨¡æ€è½¬æ¢å“åº”ä¸èƒ½ä¸ºç©º");
        assert!(response.response.len() > 300, "è·¨æ¨¡æ€è½¬æ¢ç»“æœåº”è¯¥è¯¦ç»†");

        // éªŒè¯æ˜¯å¦åŒ…å«è½¬æ¢è¦ç´ 
        let response_lower = response.response.to_lowercase();
        let conversion_elements = vec!["è½¬æ¢", "å†…å®¹", "è€ƒè™‘", "è¯„ä¼°", "ä¼˜åŒ–"];
        let mut found_elements = 0;

        for element in conversion_elements {
            if response_lower.contains(element) {
                found_elements += 1;
            }
        }

        assert!(found_elements >= 3, "è·¨æ¨¡æ€è½¬æ¢åº”è¯¥åŒ…å«è‡³å°‘3ä¸ªå…³é”®è¦ç´ ");

        println!("        âœ“ {} éªŒè¯é€šè¿‡", conversion_type);
    }

    let duration = start_time.elapsed();
    println!("  âœ… è·¨æ¨¡æ€è½¬æ¢æµ‹è¯•å®Œæˆ! è€—æ—¶: {:?}", duration);

    Ok(())
}
