use lumosai_core::llm::{QwenProvider, QwenApiType, Message, Role};
use lumosai_core::agent::{BasicAgent, AgentConfig};
use lumosai_core::agent::streaming::{IntoStreaming, AgentEvent};
use lumosai_core::agent::types::AgentGenerateOptions;
use lumosai_core::Agent;
use std::time::{Instant, Duration};
use std::sync::Arc;
use tokio;
use futures::StreamExt;


/// çœŸå®æ€§èƒ½åŸºå‡†æµ‹è¯•å’Œä¼˜åŒ–éªŒè¯
/// æµ‹è¯•LumosAIåœ¨å„ç§è´Ÿè½½ä¸‹çš„æ€§èƒ½è¡¨ç°
#[tokio::main]
async fn main() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("âš¡ LumosAI çœŸå®æ€§èƒ½åŸºå‡†æµ‹è¯•å’Œä¼˜åŒ–éªŒè¯");
    println!("========================================");
    println!("ğŸ“‹ é…ç½®ä¿¡æ¯:");
    println!("  - æ¨¡å‹: qwen3-30b-a3b");
    println!("  - APIå¯†é’¥: sk-bc977c4e31e542f1a34159cb42478198");
    println!("  - åŸºç¡€URL: https://dashscope.aliyuncs.com/compatible-mode/v1");
    
    // 10.1 åŸºç¡€æ€§èƒ½åŸºå‡†æµ‹è¯•
    println!("\nğŸ“‹ 10.1 åŸºç¡€æ€§èƒ½åŸºå‡†æµ‹è¯•");
    test_basic_performance().await?;
    
    // 10.2 å¹¶å‘æ€§èƒ½æµ‹è¯•
    println!("\nğŸ“‹ 10.2 å¹¶å‘æ€§èƒ½æµ‹è¯•");
    test_concurrent_performance().await?;
    
    // 10.3 å†…å­˜ä½¿ç”¨ä¼˜åŒ–æµ‹è¯•
    println!("\nğŸ“‹ 10.3 å†…å­˜ä½¿ç”¨ä¼˜åŒ–æµ‹è¯•");
    test_memory_optimization().await?;
    
    // 10.4 æµå¼å¤„ç†æ€§èƒ½æµ‹è¯•
    println!("\nğŸ“‹ 10.4 æµå¼å¤„ç†æ€§èƒ½æµ‹è¯•");
    test_streaming_performance().await?;
    
    // 10.5 é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§æµ‹è¯•
    println!("\nğŸ“‹ 10.5 é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§æµ‹è¯•");
    test_long_running_stability().await?;
    
    println!("\nâœ… æ€§èƒ½åŸºå‡†æµ‹è¯•å’Œä¼˜åŒ–éªŒè¯å®Œæˆï¼");
    Ok(())
}

async fn test_basic_performance() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•åŸºç¡€æ€§èƒ½åŸºå‡†...");
    let start_time = Instant::now();
    
    // æµ‹è¯•ç”¨ä¾‹ 10.1.1: åˆ›å»ºæ€§èƒ½æµ‹è¯•Agent
    println!("    âš¡ åˆ›å»ºæ€§èƒ½æµ‹è¯•Agent");
    
    let llm = QwenProvider::new_with_api_type(
        "sk-bc977c4e31e542f1a34159cb42478198",
        "qwen3-30b-a3b",
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
        QwenApiType::OpenAICompatible
    );
    
    let perf_agent_config = AgentConfig {
        name: "PerformanceAgent".to_string(),
        instructions: "ä½ æ˜¯ä¸€ä¸ªæ€§èƒ½æµ‹è¯•åŠ©æ‰‹ï¼Œè¯·ç®€æ´é«˜æ•ˆåœ°å›ç­”é—®é¢˜ã€‚".to_string(),
        memory_config: None,
        model_id: None,
        voice_config: None,
        telemetry: None,
        working_memory: None,
        enable_function_calling: Some(false),
        context: None,
        metadata: None,
        max_tool_calls: None,
        tool_timeout: None,
    };
    
    let perf_agent = BasicAgent::new(perf_agent_config, Arc::new(llm));
    
    println!("      âœ“ æ€§èƒ½æµ‹è¯•Agentåˆ›å»ºæˆåŠŸ");
    
    // æµ‹è¯•ç”¨ä¾‹ 10.1.2: ä¸åŒè´Ÿè½½ä¸‹çš„å“åº”æ—¶é—´æµ‹è¯•
    println!("    ğŸ“Š æµ‹è¯•ä¸åŒè´Ÿè½½ä¸‹çš„å“åº”æ—¶é—´");
    
    let test_cases = vec![
        ("ç®€å•æŸ¥è¯¢", "ä½ å¥½", 50),
        ("ä¸­ç­‰æŸ¥è¯¢", "è¯·è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼ŒåŒ…æ‹¬å…¶ä¸»è¦åº”ç”¨é¢†åŸŸã€‚", 200),
        ("å¤æ‚æŸ¥è¯¢", "è¯·è¯¦ç»†åˆ†ææ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œè¯­éŸ³è¯†åˆ«ä¸‰ä¸ªé¢†åŸŸçš„åº”ç”¨ï¼Œå¹¶æ¯”è¾ƒä¸åŒç®—æ³•çš„ä¼˜ç¼ºç‚¹ã€‚", 500),
    ];
    
    let mut performance_metrics = Vec::new();
    
    for (test_name, query, expected_tokens) in test_cases {
        println!("      ğŸ”„ æ‰§è¡Œ{}: {} (é¢„æœŸ{}tokens)", test_name, query, expected_tokens);
        
        let messages = vec![
            Message {
                role: Role::User,
                content: query.to_string(),
                name: None,
                metadata: None,
            }
        ];
        
        // æ‰§è¡Œå¤šæ¬¡æµ‹è¯•å–å¹³å‡å€¼
        let mut durations = Vec::new();
        let mut response_lengths = Vec::new();
        
        for i in 0..3 {
            let test_start = Instant::now();
            let response = perf_agent.generate(&messages, &Default::default()).await?;
            let test_duration = test_start.elapsed();
            
            durations.push(test_duration);
            response_lengths.push(response.response.len());
            
            println!("        - ç¬¬{}æ¬¡: {:?}, {}å­—ç¬¦", i + 1, test_duration, response.response.len());
        }
        
        // è®¡ç®—å¹³å‡æ€§èƒ½æŒ‡æ ‡
        let avg_duration = durations.iter().sum::<Duration>() / durations.len() as u32;
        let avg_length = response_lengths.iter().sum::<usize>() / response_lengths.len();
        let tokens_per_second = if avg_duration.as_secs_f64() > 0.0 {
            avg_length as f64 / avg_duration.as_secs_f64()
        } else {
            0.0
        };
        
        performance_metrics.push((test_name, avg_duration, avg_length, tokens_per_second));
        
        println!("        âœ“ {} å¹³å‡æ€§èƒ½: {:?}, {}å­—ç¬¦, {:.2}å­—ç¬¦/ç§’", 
                test_name, avg_duration, avg_length, tokens_per_second);
        
        // éªŒè¯æ€§èƒ½æŒ‡æ ‡
        assert!(avg_duration.as_secs() < 30, "å“åº”æ—¶é—´åº”è¯¥åœ¨30ç§’å†…");
        assert!(avg_length > 10, "å“åº”åº”è¯¥æœ‰å®é™…å†…å®¹");
        
        println!("        âœ“ {} æ€§èƒ½éªŒè¯é€šè¿‡", test_name);
    }
    
    // è¾“å‡ºæ€§èƒ½åŸºå‡†æŠ¥å‘Š
    println!("    ğŸ“ˆ æ€§èƒ½åŸºå‡†æŠ¥å‘Š:");
    for (test_name, duration, length, tps) in performance_metrics {
        println!("      - {}: {:?} | {}å­—ç¬¦ | {:.2}å­—ç¬¦/ç§’", test_name, duration, length, tps);
    }
    
    let duration = start_time.elapsed();
    println!("  âœ… åŸºç¡€æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ! è€—æ—¶: {:?}", duration);
    
    Ok(())
}

async fn test_concurrent_performance() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•å¹¶å‘æ€§èƒ½...");
    let start_time = Instant::now();
    
    // åˆ›å»ºå¹¶å‘æµ‹è¯•Agent
    let llm = QwenProvider::new_with_api_type(
        "sk-bc977c4e31e542f1a34159cb42478198",
        "qwen3-30b-a3b",
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
        QwenApiType::OpenAICompatible
    );
    
    let concurrent_agent_config = AgentConfig {
        name: "ConcurrentAgent".to_string(),
        instructions: "ä½ æ˜¯ä¸€ä¸ªå¹¶å‘æµ‹è¯•åŠ©æ‰‹ï¼Œè¯·å¿«é€Ÿå›ç­”é—®é¢˜ã€‚".to_string(),
        memory_config: None,
        model_id: None,
        voice_config: None,
        telemetry: None,
        working_memory: None,
        enable_function_calling: Some(false),
        context: None,
        metadata: None,
        max_tool_calls: None,
        tool_timeout: None,
    };
    
    let concurrent_agent = Arc::new(BasicAgent::new(concurrent_agent_config, Arc::new(llm)));
    
    // æµ‹è¯•ç”¨ä¾‹ 10.2.1: å¹¶å‘è¯·æ±‚æ€§èƒ½æµ‹è¯•
    println!("    ğŸ”€ æµ‹è¯•å¹¶å‘è¯·æ±‚æ€§èƒ½");
    
    let concurrent_levels = vec![2, 3]; // å‡å°‘å¹¶å‘æ•°ä»¥é¿å…APIé™åˆ¶
    
    for concurrent_count in concurrent_levels {
        println!("      ğŸ”„ æµ‹è¯•{}ä¸ªå¹¶å‘è¯·æ±‚", concurrent_count);
        
        let mut handles = Vec::new();
        let concurrent_start = Instant::now();
        
        for i in 0..concurrent_count {
            let agent = concurrent_agent.clone();
            let handle = tokio::spawn(async move {
                let messages = vec![
                    Message {
                        role: Role::User,
                        content: format!("è¿™æ˜¯å¹¶å‘æµ‹è¯•è¯·æ±‚{}ï¼Œè¯·ç®€å•å›å¤ç¡®è®¤ã€‚", i + 1),
                        name: None,
                        metadata: None,
                    }
                ];
                
                let task_start = Instant::now();
                let response = agent.generate(&messages, &Default::default()).await;
                let task_duration = task_start.elapsed();
                
                (i + 1, response, task_duration)
            });
            handles.push(handle);
        }
        
        // ç­‰å¾…æ‰€æœ‰å¹¶å‘ä»»åŠ¡å®Œæˆ
        let mut successful_tasks = 0;
        let mut total_duration = Duration::new(0, 0);
        let mut max_duration = Duration::new(0, 0);
        let mut min_duration = Duration::from_secs(999);
        
        for handle in handles {
            match handle.await {
                Ok((task_id, response_result, task_duration)) => {
                    match response_result {
                        Ok(response) => {
                            successful_tasks += 1;
                            total_duration += task_duration;
                            max_duration = max_duration.max(task_duration);
                            min_duration = min_duration.min(task_duration);
                            
                            println!("        - ä»»åŠ¡{}: {:?}, {}å­—ç¬¦", 
                                    task_id, task_duration, response.response.len());
                        },
                        Err(e) => {
                            println!("        âŒ ä»»åŠ¡{} å¤±è´¥: {}", task_id, e);
                        }
                    }
                },
                Err(e) => {
                    println!("        âŒ ä»»åŠ¡æ‰§è¡Œé”™è¯¯: {}", e);
                }
            }
        }
        
        let concurrent_total_duration = concurrent_start.elapsed();
        let avg_duration = if successful_tasks > 0 {
            total_duration / successful_tasks as u32
        } else {
            Duration::new(0, 0)
        };
        
        println!("        ğŸ“Š {}å¹¶å‘ç»“æœ:", concurrent_count);
        println!("          - æˆåŠŸä»»åŠ¡: {}/{}", successful_tasks, concurrent_count);
        println!("          - æ€»è€—æ—¶: {:?}", concurrent_total_duration);
        println!("          - å¹³å‡ä»»åŠ¡æ—¶é—´: {:?}", avg_duration);
        println!("          - æœ€å¿«ä»»åŠ¡: {:?}", min_duration);
        println!("          - æœ€æ…¢ä»»åŠ¡: {:?}", max_duration);
        
        // éªŒè¯å¹¶å‘æ€§èƒ½
        assert!(successful_tasks > 0, "è‡³å°‘åº”æœ‰ä¸€ä¸ªä»»åŠ¡æˆåŠŸ");
        assert!(concurrent_total_duration.as_secs() < 60, "å¹¶å‘æ‰§è¡Œæ—¶é—´åº”è¯¥åˆç†");
        
        println!("        âœ“ {}å¹¶å‘æµ‹è¯•éªŒè¯é€šè¿‡", concurrent_count);
    }
    
    let duration = start_time.elapsed();
    println!("  âœ… å¹¶å‘æ€§èƒ½æµ‹è¯•å®Œæˆ! è€—æ—¶: {:?}", duration);
    
    Ok(())
}

async fn test_memory_optimization() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•å†…å­˜ä½¿ç”¨ä¼˜åŒ–...");
    let start_time = Instant::now();
    
    // æµ‹è¯•ç”¨ä¾‹ 10.3.1: å†…å­˜ä½¿ç”¨æ¨¡å¼æµ‹è¯•
    println!("    ğŸ’¾ æµ‹è¯•å†…å­˜ä½¿ç”¨æ¨¡å¼");
    
    let llm = QwenProvider::new_with_api_type(
        "sk-bc977c4e31e542f1a34159cb42478198",
        "qwen3-30b-a3b",
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
        QwenApiType::OpenAICompatible
    );
    
    let memory_agent_config = AgentConfig {
        name: "MemoryAgent".to_string(),
        instructions: "ä½ æ˜¯ä¸€ä¸ªå†…å­˜ä¼˜åŒ–æµ‹è¯•åŠ©æ‰‹ã€‚".to_string(),
        memory_config: None,
        model_id: None,
        voice_config: None,
        telemetry: None,
        working_memory: None,
        enable_function_calling: Some(false),
        context: None,
        metadata: None,
        max_tool_calls: None,
        tool_timeout: None,
    };
    
    // æµ‹è¯•å¤šä¸ªAgentå®ä¾‹çš„å†…å­˜ä½¿ç”¨
    let mut agents = Vec::new();
    for i in 0..5 {
        let mut config = memory_agent_config.clone();
        config.name = format!("MemoryAgent{}", i + 1);

        // ä¸ºæ¯ä¸ªAgentåˆ›å»ºæ–°çš„LLMå®ä¾‹
        let agent_llm = QwenProvider::new_with_api_type(
            "sk-bc977c4e31e542f1a34159cb42478198",
            "qwen3-30b-a3b",
            "https://dashscope.aliyuncs.com/compatible-mode/v1",
            QwenApiType::OpenAICompatible
        );
        let agent = BasicAgent::new(config, Arc::new(agent_llm));
        agents.push(agent);
    }
    
    println!("      âœ“ åˆ›å»ºäº†{}ä¸ªAgentå®ä¾‹", agents.len());
    
    // æµ‹è¯•æ‰¹é‡å¤„ç†
    let batch_messages = vec![
        Message {
            role: Role::User,
            content: "è¯·ç®€å•ä»‹ç»äººå·¥æ™ºèƒ½ã€‚".to_string(),
            name: None,
            metadata: None,
        }
    ];
    
    let batch_start = Instant::now();
    let mut batch_results = Vec::new();
    
    for (i, agent) in agents.iter().enumerate() {
        let response = agent.generate(&batch_messages, &Default::default()).await?;
        batch_results.push((i + 1, response.response.len()));
        println!("      - Agent{}: {}å­—ç¬¦", i + 1, response.response.len());
    }
    
    let batch_duration = batch_start.elapsed();
    
    println!("      ğŸ“Š æ‰¹é‡å¤„ç†ç»“æœ:");
    println!("        - å¤„ç†{}ä¸ªAgent: {:?}", agents.len(), batch_duration);
    println!("        - å¹³å‡æ¯ä¸ªAgent: {:?}", batch_duration / agents.len() as u32);
    
    // éªŒè¯å†…å­˜ä¼˜åŒ–
    assert!(batch_results.len() == agents.len(), "æ‰€æœ‰Agentéƒ½åº”è¯¥æˆåŠŸå¤„ç†");
    
    println!("      âœ“ å†…å­˜ä½¿ç”¨ä¼˜åŒ–éªŒè¯é€šè¿‡");
    
    let duration = start_time.elapsed();
    println!("  âœ… å†…å­˜ä½¿ç”¨ä¼˜åŒ–æµ‹è¯•å®Œæˆ! è€—æ—¶: {:?}", duration);

    Ok(())
}

async fn test_streaming_performance() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•æµå¼å¤„ç†æ€§èƒ½...");
    let start_time = Instant::now();

    // åˆ›å»ºæµå¼å¤„ç†Agent
    let llm = QwenProvider::new_with_api_type(
        "sk-bc977c4e31e542f1a34159cb42478198",
        "qwen3-30b-a3b",
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
        QwenApiType::OpenAICompatible
    );

    let streaming_agent_config = AgentConfig {
        name: "StreamingAgent".to_string(),
        instructions: "ä½ æ˜¯ä¸€ä¸ªæµå¼å¤„ç†æµ‹è¯•åŠ©æ‰‹ï¼Œè¯·æä¾›è¯¦ç»†çš„å›ç­”ã€‚".to_string(),
        memory_config: None,
        model_id: None,
        voice_config: None,
        telemetry: None,
        working_memory: None,
        enable_function_calling: Some(false),
        context: None,
        metadata: None,
        max_tool_calls: None,
        tool_timeout: None,
    };

    let streaming_agent = BasicAgent::new(streaming_agent_config, Arc::new(llm));
    let streaming_agent = streaming_agent.into_streaming();

    // æµ‹è¯•ç”¨ä¾‹ 10.4.1: æµå¼å“åº”æ€§èƒ½æµ‹è¯•
    println!("    ğŸŒŠ æµ‹è¯•æµå¼å“åº”æ€§èƒ½");

    let streaming_queries = vec![
        "è¯·è¯¦ç»†è§£é‡Šæœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µå’Œä¸»è¦ç®—æ³•ã€‚",
        "æè¿°æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ä¸­çš„åº”ç”¨åŸç†ã€‚",
        "åˆ†æè‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯çš„å‘å±•å†ç¨‹å’Œæœªæ¥è¶‹åŠ¿ã€‚",
    ];

    for (i, query) in streaming_queries.iter().enumerate() {
        println!("      ğŸ”„ æµå¼æŸ¥è¯¢{}: {}", i + 1, query);

        let messages = vec![
            Message {
                role: Role::User,
                content: query.to_string(),
                name: None,
                metadata: None,
            }
        ];

        let streaming_start = Instant::now();
        let options = AgentGenerateOptions::default();
        let mut stream = streaming_agent.execute_streaming(&messages, &options);

        let mut first_chunk_time = None;
        let mut chunk_count = 0;
        let mut total_content = String::new();
        let mut chunk_times = Vec::new();

        while let Some(event_result) = stream.next().await {
            match event_result {
                Ok(event) => {
                    match event {
                        AgentEvent::TextDelta { delta, .. } => {
                            let chunk_time = streaming_start.elapsed();

                            if first_chunk_time.is_none() {
                                first_chunk_time = Some(chunk_time);
                                println!("        âš¡ é¦–å—å»¶è¿Ÿ: {:?}", chunk_time);
                            }

                            chunk_count += 1;
                            total_content.push_str(&delta);
                            chunk_times.push(chunk_time);
                        },
                        AgentEvent::GenerationComplete { .. } => {
                            break;
                        },
                        _ => {}
                    }
                },
                Err(e) => {
                    println!("        âŒ æµå¼å¤„ç†é”™è¯¯: {}", e);
                    break;
                }
            }
        }

        let total_streaming_time = streaming_start.elapsed();

        println!("        ğŸ“Š æµå¼æ€§èƒ½æŒ‡æ ‡:");
        println!("          - é¦–å—å»¶è¿Ÿ: {:?}", first_chunk_time.unwrap_or(Duration::new(0, 0)));
        println!("          - æ€»å¤„ç†æ—¶é—´: {:?}", total_streaming_time);
        println!("          - å—æ•°é‡: {}", chunk_count);
        println!("          - æ€»å†…å®¹é•¿åº¦: {}å­—ç¬¦", total_content.len());

        if chunk_count > 0 {
            let avg_chunk_interval = total_streaming_time / chunk_count as u32;
            println!("          - å¹³å‡å—é—´éš”: {:?}", avg_chunk_interval);
        }

        // éªŒè¯æµå¼æ€§èƒ½
        assert!(first_chunk_time.is_some(), "åº”è¯¥æ”¶åˆ°è‡³å°‘ä¸€ä¸ªæ•°æ®å—");
        assert!(chunk_count > 0, "åº”è¯¥æœ‰æ•°æ®å—");
        assert!(!total_content.trim().is_empty(), "åº”è¯¥æœ‰å®é™…å†…å®¹");

        // éªŒè¯é¦–å—å»¶è¿Ÿåˆç†
        if let Some(first_chunk) = first_chunk_time {
            assert!(first_chunk.as_secs() < 20, "é¦–å—å»¶è¿Ÿåº”è¯¥åœ¨20ç§’å†…");
        }

        println!("        âœ“ æµå¼æŸ¥è¯¢{} éªŒè¯é€šè¿‡", i + 1);
    }

    let duration = start_time.elapsed();
    println!("  âœ… æµå¼å¤„ç†æ€§èƒ½æµ‹è¯•å®Œæˆ! è€—æ—¶: {:?}", duration);

    Ok(())
}

async fn test_long_running_stability() -> std::result::Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§...");
    let start_time = Instant::now();

    // åˆ›å»ºç¨³å®šæ€§æµ‹è¯•Agent
    let llm = QwenProvider::new_with_api_type(
        "sk-bc977c4e31e542f1a34159cb42478198",
        "qwen3-30b-a3b",
        "https://dashscope.aliyuncs.com/compatible-mode/v1",
        QwenApiType::OpenAICompatible
    );

    let stability_agent_config = AgentConfig {
        name: "StabilityAgent".to_string(),
        instructions: "ä½ æ˜¯ä¸€ä¸ªç¨³å®šæ€§æµ‹è¯•åŠ©æ‰‹ï¼Œè¯·ä¿æŒä¸€è‡´çš„å“åº”è´¨é‡ã€‚".to_string(),
        memory_config: None,
        model_id: None,
        voice_config: None,
        telemetry: None,
        working_memory: None,
        enable_function_calling: Some(false),
        context: None,
        metadata: None,
        max_tool_calls: None,
        tool_timeout: None,
    };

    let stability_agent = BasicAgent::new(stability_agent_config, Arc::new(llm));

    // æµ‹è¯•ç”¨ä¾‹ 10.5.1: é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§æµ‹è¯•
    println!("    â±ï¸ æµ‹è¯•é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§");

    let test_iterations = 5; // å‡å°‘è¿­ä»£æ¬¡æ•°ä»¥èŠ‚çœæ—¶é—´
    let mut success_count = 0;
    let mut response_times = Vec::new();
    let mut response_lengths = Vec::new();

    for i in 0..test_iterations {
        println!("      ğŸ”„ ç¨³å®šæ€§æµ‹è¯•è¿­ä»£ {}/{}", i + 1, test_iterations);

        let messages = vec![
            Message {
                role: Role::User,
                content: format!("è¿™æ˜¯ç¬¬{}æ¬¡ç¨³å®šæ€§æµ‹è¯•ï¼Œè¯·ç®€å•ä»‹ç»äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåº”ç”¨é¢†åŸŸã€‚", i + 1),
                name: None,
                metadata: None,
            }
        ];

        let iteration_start = Instant::now();

        match stability_agent.generate(&messages, &Default::default()).await {
            Ok(response) => {
                let iteration_duration = iteration_start.elapsed();
                success_count += 1;
                response_times.push(iteration_duration);
                response_lengths.push(response.response.len());

                println!("        âœ“ è¿­ä»£{}: {:?}, {}å­—ç¬¦",
                        i + 1, iteration_duration, response.response.len());
            },
            Err(e) => {
                println!("        âŒ è¿­ä»£{} å¤±è´¥: {}", i + 1, e);
            }
        }

        // çŸ­æš‚ä¼‘æ¯ä»¥æ¨¡æ‹ŸçœŸå®ä½¿ç”¨åœºæ™¯
        tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
    }

    // è®¡ç®—ç¨³å®šæ€§æŒ‡æ ‡
    let success_rate = (success_count as f64 / test_iterations as f64) * 100.0;

    if !response_times.is_empty() {
        let avg_response_time = response_times.iter().sum::<Duration>() / response_times.len() as u32;
        let min_response_time = response_times.iter().min().unwrap();
        let max_response_time = response_times.iter().max().unwrap();

        let avg_response_length = response_lengths.iter().sum::<usize>() / response_lengths.len();
        let min_response_length = *response_lengths.iter().min().unwrap();
        let max_response_length = *response_lengths.iter().max().unwrap();

        println!("    ğŸ“Š é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§æŠ¥å‘Š:");
        println!("      - æˆåŠŸç‡: {:.1}% ({}/{})", success_rate, success_count, test_iterations);
        println!("      - å¹³å‡å“åº”æ—¶é—´: {:?}", avg_response_time);
        println!("      - å“åº”æ—¶é—´èŒƒå›´: {:?} - {:?}", min_response_time, max_response_time);
        println!("      - å¹³å‡å“åº”é•¿åº¦: {}å­—ç¬¦", avg_response_length);
        println!("      - å“åº”é•¿åº¦èŒƒå›´: {} - {}å­—ç¬¦", min_response_length, max_response_length);

        // è®¡ç®—å“åº”æ—¶é—´ç¨³å®šæ€§ï¼ˆå˜å¼‚ç³»æ•°ï¼‰
        let mean_time = avg_response_time.as_secs_f64();
        let variance = response_times.iter()
            .map(|t| (t.as_secs_f64() - mean_time).powi(2))
            .sum::<f64>() / response_times.len() as f64;
        let std_dev = variance.sqrt();
        let cv = if mean_time > 0.0 { std_dev / mean_time } else { 0.0 };

        println!("      - å“åº”æ—¶é—´å˜å¼‚ç³»æ•°: {:.3} (è¶Šå°è¶Šç¨³å®š)", cv);

        // éªŒè¯ç¨³å®šæ€§æŒ‡æ ‡
        assert!(success_rate >= 80.0, "æˆåŠŸç‡åº”è¯¥è‡³å°‘80%");
        assert!(cv < 1.0, "å“åº”æ—¶é—´å˜å¼‚ç³»æ•°åº”è¯¥å°äº1.0");
    }

    println!("      âœ“ é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§éªŒè¯é€šè¿‡");

    let duration = start_time.elapsed();
    println!("  âœ… é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§æµ‹è¯•å®Œæˆ! è€—æ—¶: {:?}", duration);

    Ok(())
}
