//! AIèƒ½åŠ›æ‰©å±•æ¼”ç¤º
//! 
//! å±•ç¤ºLumos.ai AIèƒ½åŠ›æ‰©å±•çš„å®Œæ•´åŠŸèƒ½

use lumosai_ai_extensions::*;
use std::collections::HashMap;

#[tokio::main]
async fn main() -> Result<()> {
    println!("ğŸ§  Lumos.ai AIèƒ½åŠ›æ‰©å±•æ¼”ç¤º");
    println!("=" .repeat(50));
    
    // æ¼”ç¤ºå¤šæ¨¡æ€å¤„ç†
    demo_multimodal_processing().await?;
    
    // æ¼”ç¤ºæ¨ç†èƒ½åŠ›
    demo_reasoning_capabilities().await?;
    
    // æ¼”ç¤ºé¢†åŸŸé€‚é…
    demo_domain_adaptation().await?;
    
    // æ¼”ç¤ºçŸ¥è¯†å›¾è°±
    demo_knowledge_graph().await?;
    
    // æ¼”ç¤ºæ¨¡å‹æ¨ç†
    demo_model_inference().await?;
    
    // æ¼”ç¤ºç»¼åˆAIèƒ½åŠ›
    demo_integrated_ai_capabilities().await?;
    
    println!("\nğŸ‰ AIèƒ½åŠ›æ‰©å±•æ¼”ç¤ºå®Œæˆï¼");
    println!("\nğŸš€ æ”¯æŒçš„AIèƒ½åŠ›:");
    println!("  ğŸ‘ï¸  å¤šæ¨¡æ€å¤„ç†: å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ã€æ–‡æ¡£");
    println!("  ğŸ§  é«˜çº§æ¨ç†: é€»è¾‘ã€å› æœã€ç±»æ¯”ã€å½’çº³ã€æ¼”ç»");
    println!("  ğŸ¢ é¢†åŸŸé€‚é…: é‡‘èã€åŒ»ç–—ã€æ•™è‚²ã€æ³•å¾‹ç­‰ä¸“ä¸šé¢†åŸŸ");
    println!("  ğŸ•¸ï¸  çŸ¥è¯†å›¾è°±: å®ä½“è¯†åˆ«ã€å…³ç³»æŠ½å–ã€çŸ¥è¯†æ¨ç†");
    println!("  âš¡ æ¨¡å‹æ¨ç†: ONNXã€PyTorchã€TensorFlowæ¨¡å‹æ”¯æŒ");
    
    Ok(())
}

/// æ¼”ç¤ºå¤šæ¨¡æ€å¤„ç†
async fn demo_multimodal_processing() -> Result<()> {
    println!("\nğŸ‘ï¸  æ¼”ç¤ºï¼šå¤šæ¨¡æ€å¤„ç†");
    println!("-" .repeat(30));
    
    // åˆ›å»ºå¤šæ¨¡æ€å¤„ç†å™¨
    let config = AiCapabilityConfig::default();
    let processor = MultimodalProcessor::new(config.multimodal).await?;
    
    // æ¼”ç¤ºå›¾åƒå¤„ç†
    println!("ğŸ–¼ï¸  å›¾åƒå¤„ç†:");
    let image_input = MultimodalInput::Image {
        data: vec![0u8; 1024], // æ¨¡æ‹Ÿå›¾åƒæ•°æ®
        format: "png".to_string(),
        metadata: {
            let mut meta = HashMap::new();
            meta.insert("source".to_string(), "camera".to_string());
            meta
        },
    };
    
    match processor.process(image_input).await {
        Ok(result) => {
            println!("   âœ… å¤„ç†æˆåŠŸ");
            println!("   ğŸ“Š ç»“æœæ•°é‡: {}", result.results.len());
            println!("   ğŸ¯ ç½®ä¿¡åº¦: {:.2}", result.confidence);
            println!("   â±ï¸  å¤„ç†æ—¶é—´: {}ms", result.processing_time_ms);
            
            for (i, modal_result) in result.results.iter().enumerate() {
                match modal_result {
                    ModalityResult::Vision(vision_result) => {
                        println!("   ğŸ” è§†è§‰åˆ†æ {}:", i + 1);
                        println!("      å›¾åƒå°ºå¯¸: {}x{}", 
                                vision_result.image_info.width, 
                                vision_result.image_info.height);
                        if let Some(ocr) = &vision_result.ocr_result {
                            println!("      OCRæ–‡æœ¬: {}", ocr.text);
                        }
                        if let Some(analysis) = &vision_result.analysis_result {
                            println!("      å›¾åƒæè¿°: {}", analysis.description);
                            println!("      æ ‡ç­¾æ•°é‡: {}", analysis.tags.len());
                        }
                    }
                    _ => {}
                }
            }
        }
        Err(e) => println!("   âŒ å¤„ç†å¤±è´¥: {}", e),
    }
    
    // æ¼”ç¤ºéŸ³é¢‘å¤„ç†
    println!("\nğŸµ éŸ³é¢‘å¤„ç†:");
    let audio_input = MultimodalInput::Audio {
        data: vec![0u8; 2048], // æ¨¡æ‹ŸéŸ³é¢‘æ•°æ®
        format: "wav".to_string(),
        sample_rate: 16000,
        channels: 1,
        metadata: HashMap::new(),
    };
    
    match processor.process(audio_input).await {
        Ok(result) => {
            println!("   âœ… å¤„ç†æˆåŠŸ");
            println!("   ğŸ¯ ç½®ä¿¡åº¦: {:.2}", result.confidence);
            
            for modal_result in &result.results {
                if let ModalityResult::Audio(audio_result) = modal_result {
                    println!("   ğŸ¤ éŸ³é¢‘åˆ†æ:");
                    if let Some(transcription) = &audio_result.transcription {
                        println!("      è½¬å½•æ–‡æœ¬: {}", transcription);
                    }
                    if let Some(language) = &audio_result.language {
                        println!("      æ£€æµ‹è¯­è¨€: {}", language);
                    }
                    println!("      éŸ³é¢‘æ—¶é•¿: {:.1}ç§’", audio_result.duration_seconds);
                }
            }
        }
        Err(e) => println!("   âŒ å¤„ç†å¤±è´¥: {}", e),
    }
    
    // æ¼”ç¤ºæ–‡æœ¬å¤„ç†
    println!("\nğŸ“ æ–‡æœ¬å¤„ç†:");
    let text_input = MultimodalInput::Text {
        content: "è¿™æ˜¯ä¸€ä¸ªå¾ˆæ£’çš„AIç³»ç»Ÿï¼Œå®ƒèƒ½å¤Ÿå¤„ç†å¤šç§æ¨¡æ€çš„æ•°æ®ï¼ŒåŒ…æ‹¬æ–‡æœ¬ã€å›¾åƒå’ŒéŸ³é¢‘ã€‚".to_string(),
        language: Some("zh".to_string()),
        metadata: HashMap::new(),
    };
    
    match processor.process(text_input).await {
        Ok(result) => {
            println!("   âœ… å¤„ç†æˆåŠŸ");
            
            for modal_result in &result.results {
                if let ModalityResult::Text(text_result) = modal_result {
                    println!("   ğŸ“„ æ–‡æœ¬åˆ†æ:");
                    if let Some(language) = &text_result.detected_language {
                        println!("      æ£€æµ‹è¯­è¨€: {}", language);
                    }
                    if let Some(sentiment) = &text_result.sentiment {
                        println!("      æƒ…æ„Ÿåˆ†æ: {} (ç½®ä¿¡åº¦: {:.2})", sentiment.label, sentiment.confidence);
                    }
                    println!("      å®ä½“æ•°é‡: {}", text_result.entities.len());
                    println!("      å…³é”®è¯æ•°é‡: {}", text_result.keywords.len());
                    
                    if !text_result.keywords.is_empty() {
                        println!("      å…³é”®è¯:");
                        for keyword in text_result.keywords.iter().take(3) {
                            println!("        - {} (åˆ†æ•°: {:.2})", keyword.text, keyword.score);
                        }
                    }
                }
            }
        }
        Err(e) => println!("   âŒ å¤„ç†å¤±è´¥: {}", e),
    }
    
    Ok(())
}

/// æ¼”ç¤ºæ¨ç†èƒ½åŠ›
async fn demo_reasoning_capabilities() -> Result<()> {
    println!("\nğŸ§  æ¼”ç¤ºï¼šæ¨ç†èƒ½åŠ›");
    println!("-" .repeat(30));
    
    // åˆ›å»ºæ¨ç†å¼•æ“
    let config = AiCapabilityConfig::default();
    let reasoning_engine = ReasoningEngine::new(config.reasoning).await?;
    
    // æ¼”ç¤ºé€»è¾‘æ¨ç†
    println!("ğŸ” é€»è¾‘æ¨ç†:");
    let logical_query = ReasoningQuery {
        query_type: ReasoningType::Logical,
        premises: vec![
            "æ‰€æœ‰äººéƒ½æ˜¯ä¼šæ­»çš„".to_string(),
            "è‹æ ¼æ‹‰åº•æ˜¯äºº".to_string(),
        ],
        question: "è‹æ ¼æ‹‰åº•æ˜¯å¦ä¼šæ­»ï¼Ÿ".to_string(),
        context: HashMap::new(),
        parameters: ReasoningParameters::default(),
    };
    
    match reasoning_engine.reason(logical_query).await {
        Ok(result) => {
            println!("   âœ… æ¨ç†æˆåŠŸ");
            println!("   ğŸ“ ç»“è®º: {}", result.conclusion);
            println!("   ğŸ¯ ç½®ä¿¡åº¦: {:.2}", result.confidence);
            println!("   ğŸ”— æ¨ç†æ­¥æ•°: {}", result.reasoning_chain.len());
            println!("   â±ï¸  æ¨ç†æ—¶é—´: {}ms", result.statistics.reasoning_time_ms);
            
            if !result.reasoning_chain.is_empty() {
                println!("   ğŸ§© æ¨ç†é“¾:");
                for step in &result.reasoning_chain {
                    println!("      æ­¥éª¤{}: {} -> {}", 
                            step.step_number, 
                            step.rule, 
                            step.output_conclusion);
                }
            }
        }
        Err(e) => println!("   âŒ æ¨ç†å¤±è´¥: {}", e),
    }
    
    // æ¼”ç¤ºå› æœæ¨ç†
    println!("\nğŸ”„ å› æœæ¨ç†:");
    let causal_query = ReasoningQuery {
        query_type: ReasoningType::Causal,
        premises: vec![
            "ä¸‹é›¨æ—¶åœ°é¢ä¼šæ¹¿".to_string(),
            "åœ°é¢æ˜¯æ¹¿çš„".to_string(),
        ],
        question: "æ˜¯å¦ä¸‹é›¨äº†ï¼Ÿ".to_string(),
        context: HashMap::new(),
        parameters: ReasoningParameters::default(),
    };
    
    match reasoning_engine.reason(causal_query).await {
        Ok(result) => {
            println!("   âœ… æ¨ç†æˆåŠŸ");
            println!("   ğŸ“ ç»“è®º: {}", result.conclusion);
            println!("   ğŸ¯ ç½®ä¿¡åº¦: {:.2}", result.confidence);
            println!("   ğŸ“Š æ¢ç´¢å‡è®¾æ•°: {}", result.statistics.hypotheses_explored);
        }
        Err(e) => println!("   âŒ æ¨ç†å¤±è´¥: {}", e),
    }
    
    // æ¼”ç¤ºç±»æ¯”æ¨ç†
    println!("\nğŸ”— ç±»æ¯”æ¨ç†:");
    let analogical_query = ReasoningQuery {
        query_type: ReasoningType::Analogical,
        premises: vec![
            "åŸå­æ ¸å°±åƒå¤ªé˜³ç³»çš„ä¸­å¿ƒ".to_string(),
            "ç”µå­å›´ç»•åŸå­æ ¸è¿åŠ¨".to_string(),
        ],
        question: "ç”µå­çš„è¿åŠ¨ç±»ä¼¼äºä»€ä¹ˆï¼Ÿ".to_string(),
        context: HashMap::new(),
        parameters: ReasoningParameters::default(),
    };
    
    match reasoning_engine.reason(analogical_query).await {
        Ok(result) => {
            println!("   âœ… æ¨ç†æˆåŠŸ");
            println!("   ğŸ“ ç»“è®º: {}", result.conclusion);
            println!("   ğŸ¯ ç½®ä¿¡åº¦: {:.2}", result.confidence);
        }
        Err(e) => println!("   âŒ æ¨ç†å¤±è´¥: {}", e),
    }
    
    Ok(())
}

/// æ¼”ç¤ºé¢†åŸŸé€‚é…
async fn demo_domain_adaptation() -> Result<()> {
    println!("\nğŸ¢ æ¼”ç¤ºï¼šé¢†åŸŸé€‚é…");
    println!("-" .repeat(30));
    
    // åˆ›å»ºé¢†åŸŸé€‚é…å™¨
    let config = AiCapabilityConfig::default();
    let domain_adapter = DomainAdapter::new(config.domain).await?;
    
    let domains = vec![
        ("finance", "åˆ†æè¿™å®¶å…¬å¸çš„è´¢åŠ¡çŠ¶å†µå’ŒæŠ•èµ„ä»·å€¼"),
        ("healthcare", "æ‚£è€…å‡ºç°å‘çƒ­ã€å’³å—½ç—‡çŠ¶ï¼Œè¯·æä¾›è¯Šæ–­å»ºè®®"),
        ("education", "å¦‚ä½•æé«˜å­¦ç”Ÿçš„æ•°å­¦å­¦ä¹ æ•ˆæœ"),
        ("legal", "åˆ†æè¿™ä»½åˆåŒçš„æ³•å¾‹é£é™©å’Œæ³¨æ„äº‹é¡¹"),
    ];
    
    for (domain, content) in domains {
        println!("ğŸ¯ {} é¢†åŸŸé€‚é…:", domain);
        
        let input = DomainInput {
            content: content.to_string(),
            domain: domain.to_string(),
            context: HashMap::new(),
        };
        
        match domain_adapter.adapt(domain, input).await {
            Ok(result) => {
                println!("   âœ… é€‚é…æˆåŠŸ");
                println!("   ğŸ“ é€‚é…å†…å®¹: {}", result.adapted_content);
                println!("   ğŸ¯ ç½®ä¿¡åº¦: {:.2}", result.confidence);
                println!("   ğŸ’¡ é¢†åŸŸæ´å¯Ÿ: {:?}", result.domain_insights);
            }
            Err(e) => println!("   âŒ é€‚é…å¤±è´¥: {}", e),
        }
        println!();
    }
    
    Ok(())
}

/// æ¼”ç¤ºçŸ¥è¯†å›¾è°±
async fn demo_knowledge_graph() -> Result<()> {
    println!("\nğŸ•¸ï¸  æ¼”ç¤ºï¼šçŸ¥è¯†å›¾è°±");
    println!("-" .repeat(30));
    
    // åˆ›å»ºçŸ¥è¯†å›¾è°±
    let config = AiCapabilityConfig::default();
    let knowledge_graph = KnowledgeGraph::new(config.knowledge).await?;
    
    println!("ğŸ” çŸ¥è¯†æŸ¥è¯¢:");
    let query = KnowledgeQuery {
        query_type: "entity_search".to_string(),
        entities: vec!["äººå·¥æ™ºèƒ½".to_string(), "æœºå™¨å­¦ä¹ ".to_string()],
        relations: vec!["åŒ…å«".to_string(), "åº”ç”¨äº".to_string()],
        constraints: HashMap::new(),
    };
    
    match knowledge_graph.query(query).await {
        Ok(result) => {
            println!("   âœ… æŸ¥è¯¢æˆåŠŸ");
            println!("   ğŸ“Š å®ä½“æ•°é‡: {}", result.entities.len());
            println!("   ğŸ”— å…³ç³»æ•°é‡: {}", result.relations.len());
            println!("   ğŸ¯ ç½®ä¿¡åº¦: {:.2}", result.confidence);
            
            if !result.entities.is_empty() {
                println!("   ğŸ·ï¸  å®ä½“åˆ—è¡¨:");
                for entity in &result.entities {
                    println!("      - {} (ç±»å‹: {})", entity.name, entity.entity_type);
                }
            }
            
            if !result.relations.is_empty() {
                println!("   ğŸ”— å…³ç³»åˆ—è¡¨:");
                for relation in &result.relations {
                    println!("      - {} -> {} ({})", 
                            relation.source_entity, 
                            relation.target_entity, 
                            relation.relation_type);
                }
            }
        }
        Err(e) => println!("   âŒ æŸ¥è¯¢å¤±è´¥: {}", e),
    }
    
    Ok(())
}

/// æ¼”ç¤ºæ¨¡å‹æ¨ç†
async fn demo_model_inference() -> Result<()> {
    println!("\nâš¡ æ¼”ç¤ºï¼šæ¨¡å‹æ¨ç†");
    println!("-" .repeat(30));
    
    // åˆ›å»ºæ¨ç†å¼•æ“
    let config = AiCapabilityConfig::default();
    let inference_engine = InferenceEngine::new(config.inference).await?;
    
    println!("ğŸ¤– æ¨¡å‹æ¨ç†:");
    let input = InferenceInput {
        data: serde_json::json!({
            "image": [0.1, 0.2, 0.3, 0.4],
            "metadata": {
                "width": 224,
                "height": 224,
                "channels": 3
            }
        }),
        input_format: "tensor".to_string(),
        preprocessing: None,
    };
    
    match inference_engine.infer("image_classifier", input).await {
        Ok(result) => {
            println!("   âœ… æ¨ç†æˆåŠŸ");
            println!("   ğŸ“Š ç»“æœ: {}", result.result);
            println!("   ğŸ¯ ç½®ä¿¡åº¦: {:.2}", result.confidence);
            println!("   â±ï¸  æ¨ç†æ—¶é—´: {}ms", result.inference_time_ms);
            println!("   ğŸ¤– æ¨¡å‹ä¿¡æ¯:");
            println!("      åç§°: {}", result.model_info.model_name);
            println!("      ç‰ˆæœ¬: {}", result.model_info.model_version);
            println!("      åç«¯: {}", result.model_info.backend);
            println!("      è¾“å…¥å½¢çŠ¶: {:?}", result.model_info.input_shape);
            println!("      è¾“å‡ºå½¢çŠ¶: {:?}", result.model_info.output_shape);
        }
        Err(e) => println!("   âŒ æ¨ç†å¤±è´¥: {}", e),
    }
    
    Ok(())
}

/// æ¼”ç¤ºç»¼åˆAIèƒ½åŠ›
async fn demo_integrated_ai_capabilities() -> Result<()> {
    println!("\nğŸš€ æ¼”ç¤ºï¼šç»¼åˆAIèƒ½åŠ›");
    println!("-" .repeat(30));
    
    // åˆ›å»ºAIæ‰©å±•ç®¡ç†å™¨
    let config = AiCapabilityConfig::default();
    let ai_manager = AiExtensionManager::new(config).await?;
    
    println!("ğŸ¯ ç»¼åˆåœºæ™¯ï¼šæ™ºèƒ½æ–‡æ¡£åˆ†æ");
    
    // 1. å¤šæ¨¡æ€å¤„ç† - æ–‡æ¡£
    println!("   1ï¸âƒ£ æ–‡æ¡£å¤„ç†...");
    let document_input = MultimodalInput::Document {
        data: vec![0u8; 4096], // æ¨¡æ‹ŸPDFæ•°æ®
        format: "pdf".to_string(),
        filename: "financial_report.pdf".to_string(),
        metadata: HashMap::new(),
    };
    
    let multimodal_result = ai_manager.process_multimodal(document_input).await?;
    println!("      âœ… æ–‡æ¡£å¤„ç†å®Œæˆï¼Œç½®ä¿¡åº¦: {:.2}", multimodal_result.confidence);
    
    // 2. é¢†åŸŸé€‚é… - é‡‘èé¢†åŸŸ
    println!("   2ï¸âƒ£ é‡‘èé¢†åŸŸé€‚é…...");
    let domain_input = DomainInput {
        content: "å…¬å¸æœ¬å­£åº¦è¥æ”¶å¢é•¿15%ï¼Œå‡€åˆ©æ¶¦ç‡æå‡è‡³12%".to_string(),
        domain: "finance".to_string(),
        context: HashMap::new(),
    };
    
    let domain_result = ai_manager.adapt_domain("finance", domain_input).await?;
    println!("      âœ… é¢†åŸŸé€‚é…å®Œæˆï¼Œç½®ä¿¡åº¦: {:.2}", domain_result.confidence);
    
    // 3. æ¨ç†åˆ†æ
    println!("   3ï¸âƒ£ æ¨ç†åˆ†æ...");
    let reasoning_query = ReasoningQuery {
        query_type: ReasoningType::Inductive,
        premises: vec![
            "è¥æ”¶å¢é•¿15%".to_string(),
            "å‡€åˆ©æ¶¦ç‡æå‡è‡³12%".to_string(),
            "å¸‚åœºä»½é¢ç¨³å®š".to_string(),
        ],
        question: "å…¬å¸æœªæ¥å‘å±•è¶‹åŠ¿å¦‚ä½•ï¼Ÿ".to_string(),
        context: HashMap::new(),
        parameters: ReasoningParameters::default(),
    };
    
    let reasoning_result = ai_manager.reason(reasoning_query).await?;
    println!("      âœ… æ¨ç†åˆ†æå®Œæˆï¼Œç½®ä¿¡åº¦: {:.2}", reasoning_result.confidence);
    
    // 4. ç»¼åˆç»“è®º
    println!("   4ï¸âƒ£ ç»¼åˆç»“è®º:");
    println!("      ğŸ“Š æ–‡æ¡£åˆ†æ: æˆåŠŸæå–å…³é”®è´¢åŠ¡æ•°æ®");
    println!("      ğŸ¢ é¢†åŸŸé€‚é…: åº”ç”¨é‡‘èåˆ†ææ¡†æ¶");
    println!("      ğŸ§  æ¨ç†ç»“è®º: {}", reasoning_result.conclusion);
    println!("      ğŸ¯ æ•´ä½“ç½®ä¿¡åº¦: {:.2}", 
            (multimodal_result.confidence + domain_result.confidence + reasoning_result.confidence) / 3.0);
    
    println!("\nğŸ’¡ AIèƒ½åŠ›ç‰¹æ€§æ€»ç»“:");
    println!("   âœ… å¤šæ¨¡æ€èåˆ: æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ç»Ÿä¸€å¤„ç†");
    println!("   âœ… æ™ºèƒ½æ¨ç†: 6ç§æ¨ç†ç±»å‹ï¼Œæ”¯æŒå¤æ‚é€»è¾‘åˆ†æ");
    println!("   âœ… é¢†åŸŸä¸“ç²¾: é‡‘èã€åŒ»ç–—ã€æ•™è‚²ã€æ³•å¾‹ç­‰ä¸“ä¸šé€‚é…");
    println!("   âœ… çŸ¥è¯†å¢å¼º: å®ä½“è¯†åˆ«ã€å…³ç³»æŠ½å–ã€çŸ¥è¯†æ¨ç†");
    println!("   âœ… é«˜æ•ˆæ¨ç†: å¤šåç«¯æ”¯æŒï¼Œä¼˜åŒ–çš„æ¨ç†æ€§èƒ½");
    println!("   âœ… å¯æ‰©å±•æ€§: æ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒè‡ªå®šä¹‰æ‰©å±•");
    
    Ok(())
}
