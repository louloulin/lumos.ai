#!/usr/bin/env python3
"""
LumosAI å‘å¸ƒè´¨é‡æ£€æŸ¥å·¥å…·
ç”¨äºæ£€æŸ¥ä»£ç è´¨é‡ã€æµ‹è¯•è¦†ç›–ç‡ã€æ–‡æ¡£å®Œæ•´æ€§ç­‰
"""

import os
import re
import sys
import json
import subprocess
import argparse
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass

@dataclass
class QualityMetrics:
    """è´¨é‡æŒ‡æ ‡"""
    test_coverage: float
    clippy_warnings: int
    doc_coverage: float
    code_lines: int
    test_lines: int
    dependency_count: int
    security_issues: int
    performance_score: float

class QualityChecker:
    """è´¨é‡æ£€æŸ¥å™¨"""
    
    def __init__(self, workspace_root: Path):
        self.workspace_root = workspace_root
        self.metrics = QualityMetrics(0, 0, 0, 0, 0, 0, 0, 0)
    
    def run_command(self, cmd: List[str], capture_output: bool = True) -> Tuple[int, str, str]:
        """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
        try:
            result = subprocess.run(
                cmd,
                cwd=self.workspace_root,
                capture_output=capture_output,
                text=True,
                timeout=300
            )
            return result.returncode, result.stdout, result.stderr
        except subprocess.TimeoutExpired:
            return -1, "", "å‘½ä»¤è¶…æ—¶"
        except Exception as e:
            return -1, "", str(e)
    
    def check_test_coverage(self) -> float:
        """æ£€æŸ¥æµ‹è¯•è¦†ç›–ç‡"""
        print("ğŸ§ª æ£€æŸ¥æµ‹è¯•è¦†ç›–ç‡...")
        
        # æ£€æŸ¥æ˜¯å¦å®‰è£…äº† cargo-tarpaulin
        code, _, _ = self.run_command(["cargo", "tarpaulin", "--version"])
        if code != 0:
            print("âš ï¸  cargo-tarpaulin æœªå®‰è£…ï¼Œè·³è¿‡è¦†ç›–ç‡æ£€æŸ¥")
            return 0.0
        
        # è¿è¡Œè¦†ç›–ç‡æµ‹è¯•
        code, stdout, stderr = self.run_command([
            "cargo", "tarpaulin", 
            "--all-features", 
            "--workspace",
            "--out", "json",
            "--output-dir", "target/tarpaulin"
        ])
        
        if code != 0:
            print(f"âŒ è¦†ç›–ç‡æµ‹è¯•å¤±è´¥: {stderr}")
            return 0.0
        
        # è§£æè¦†ç›–ç‡ç»“æœ
        try:
            coverage_file = self.workspace_root / "target/tarpaulin/tarpaulin-report.json"
            if coverage_file.exists():
                with open(coverage_file, 'r') as f:
                    data = json.load(f)
                    coverage = data.get('coverage', 0.0)
                    print(f"âœ… æµ‹è¯•è¦†ç›–ç‡: {coverage:.1f}%")
                    return coverage
        except Exception as e:
            print(f"âš ï¸  è§£æè¦†ç›–ç‡ç»“æœå¤±è´¥: {e}")
        
        return 0.0
    
    def check_clippy_warnings(self) -> int:
        """æ£€æŸ¥ Clippy è­¦å‘Š"""
        print("ğŸ” æ£€æŸ¥ Clippy è­¦å‘Š...")
        
        code, stdout, stderr = self.run_command([
            "cargo", "clippy", 
            "--all-features", 
            "--workspace",
            "--message-format=json"
        ])
        
        warnings = 0
        for line in stdout.split('\n'):
            if line.strip():
                try:
                    msg = json.loads(line)
                    if msg.get('reason') == 'compiler-message':
                        level = msg.get('message', {}).get('level')
                        if level == 'warning':
                            warnings += 1
                except json.JSONDecodeError:
                    continue
        
        print(f"âœ… Clippy è­¦å‘Šæ•°: {warnings}")
        return warnings
    
    def check_doc_coverage(self) -> float:
        """æ£€æŸ¥æ–‡æ¡£è¦†ç›–ç‡"""
        print("ğŸ“š æ£€æŸ¥æ–‡æ¡£è¦†ç›–ç‡...")
        
        # è¿è¡Œæ–‡æ¡£æ„å»ºå¹¶æ£€æŸ¥ç¼ºå¤±çš„æ–‡æ¡£
        code, stdout, stderr = self.run_command([
            "cargo", "doc", 
            "--all-features", 
            "--workspace",
            "--no-deps"
        ])
        
        if code != 0:
            print(f"âŒ æ–‡æ¡£æ„å»ºå¤±è´¥: {stderr}")
            return 0.0
        
        # ç»Ÿè®¡æ–‡æ¡£è¦†ç›–ç‡ï¼ˆç®€å•å®ç°ï¼‰
        doc_warnings = stderr.count("missing documentation")
        total_items = stderr.count("warning:") + 100  # ä¼°ç®—
        
        if total_items > 0:
            coverage = max(0, (total_items - doc_warnings) / total_items * 100)
        else:
            coverage = 100.0
        
        print(f"âœ… æ–‡æ¡£è¦†ç›–ç‡: {coverage:.1f}%")
        return coverage
    
    def count_code_lines(self) -> Tuple[int, int]:
        """ç»Ÿè®¡ä»£ç è¡Œæ•°"""
        print("ğŸ“Š ç»Ÿè®¡ä»£ç è¡Œæ•°...")
        
        code_lines = 0
        test_lines = 0
        
        # ç»Ÿè®¡ Rust æºæ–‡ä»¶
        for rust_file in self.workspace_root.rglob("*.rs"):
            if "target" in str(rust_file):
                continue
            
            try:
                with open(rust_file, 'r', encoding='utf-8') as f:
                    lines = len([line for line in f if line.strip() and not line.strip().startswith('//')])
                
                if "test" in str(rust_file) or "/tests/" in str(rust_file):
                    test_lines += lines
                else:
                    code_lines += lines
            except Exception:
                continue
        
        print(f"âœ… ä»£ç è¡Œæ•°: {code_lines}, æµ‹è¯•è¡Œæ•°: {test_lines}")
        return code_lines, test_lines
    
    def count_dependencies(self) -> int:
        """ç»Ÿè®¡ä¾èµ–æ•°é‡"""
        print("ğŸ“¦ ç»Ÿè®¡ä¾èµ–æ•°é‡...")
        
        code, stdout, stderr = self.run_command([
            "cargo", "tree", "--depth=1"
        ])
        
        if code != 0:
            print(f"âš ï¸  æ— æ³•ç»Ÿè®¡ä¾èµ–: {stderr}")
            return 0
        
        # ç®€å•ç»Ÿè®¡ç›´æ¥ä¾èµ–
        deps = len([line for line in stdout.split('\n') if line.startswith('â”œâ”€â”€') or line.startswith('â””â”€â”€')])
        print(f"âœ… ç›´æ¥ä¾èµ–æ•°: {deps}")
        return deps
    
    def check_security_issues(self) -> int:
        """æ£€æŸ¥å®‰å…¨é—®é¢˜"""
        print("ğŸ”’ æ£€æŸ¥å®‰å…¨é—®é¢˜...")
        
        # æ£€æŸ¥æ˜¯å¦å®‰è£…äº† cargo-audit
        code, _, _ = self.run_command(["cargo", "audit", "--version"])
        if code != 0:
            print("âš ï¸  cargo-audit æœªå®‰è£…ï¼Œè·³è¿‡å®‰å…¨æ£€æŸ¥")
            return 0
        
        code, stdout, stderr = self.run_command([
            "cargo", "audit", "--json"
        ])
        
        if code != 0:
            print(f"âš ï¸  å®‰å…¨æ£€æŸ¥å¤±è´¥: {stderr}")
            return 0
        
        try:
            data = json.loads(stdout)
            vulnerabilities = len(data.get('vulnerabilities', {}).get('list', []))
            print(f"âœ… å®‰å…¨é—®é¢˜æ•°: {vulnerabilities}")
            return vulnerabilities
        except json.JSONDecodeError:
            print("âš ï¸  è§£æå®‰å…¨æ£€æŸ¥ç»“æœå¤±è´¥")
            return 0
    
    def check_performance(self) -> float:
        """æ£€æŸ¥æ€§èƒ½ï¼ˆåŸºå‡†æµ‹è¯•ï¼‰"""
        print("âš¡ æ£€æŸ¥æ€§èƒ½...")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åŸºå‡†æµ‹è¯•
        bench_files = list(self.workspace_root.rglob("benches/*.rs"))
        if not bench_files:
            print("âš ï¸  æœªæ‰¾åˆ°åŸºå‡†æµ‹è¯•")
            return 0.0
        
        code, stdout, stderr = self.run_command([
            "cargo", "bench", "--no-run"
        ])
        
        if code == 0:
            print("âœ… åŸºå‡†æµ‹è¯•ç¼–è¯‘æˆåŠŸ")
            return 85.0  # å‡è®¾æ€§èƒ½åˆ†æ•°
        else:
            print(f"âŒ åŸºå‡†æµ‹è¯•ç¼–è¯‘å¤±è´¥: {stderr}")
            return 0.0
    
    def run_all_checks(self) -> QualityMetrics:
        """è¿è¡Œæ‰€æœ‰è´¨é‡æ£€æŸ¥"""
        print("ğŸš€ å¼€å§‹è´¨é‡æ£€æŸ¥...")
        print("=" * 50)
        
        # è¿è¡Œå„é¡¹æ£€æŸ¥
        self.metrics.test_coverage = self.check_test_coverage()
        self.metrics.clippy_warnings = self.check_clippy_warnings()
        self.metrics.doc_coverage = self.check_doc_coverage()
        self.metrics.code_lines, self.metrics.test_lines = self.count_code_lines()
        self.metrics.dependency_count = self.count_dependencies()
        self.metrics.security_issues = self.check_security_issues()
        self.metrics.performance_score = self.check_performance()
        
        return self.metrics
    
    def generate_report(self, metrics: QualityMetrics) -> str:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        
        # è®¡ç®—æ€»ä½“è´¨é‡åˆ†æ•°
        quality_score = self._calculate_quality_score(metrics)
        
        report = f"""
# LumosAI è´¨é‡æŠ¥å‘Š

## ğŸ“Š æ€»ä½“è¯„åˆ†: {quality_score:.1f}/100

## ğŸ“ˆ è¯¦ç»†æŒ‡æ ‡

### ğŸ§ª æµ‹è¯•è´¨é‡
- **æµ‹è¯•è¦†ç›–ç‡**: {metrics.test_coverage:.1f}%
- **æµ‹è¯•ä»£ç è¡Œæ•°**: {metrics.test_lines:,}
- **ä»£ç æµ‹è¯•æ¯”**: {(metrics.test_lines / max(metrics.code_lines, 1) * 100):.1f}%

### ğŸ” ä»£ç è´¨é‡  
- **Clippy è­¦å‘Š**: {metrics.clippy_warnings}
- **ä»£ç è¡Œæ•°**: {metrics.code_lines:,}
- **æ–‡æ¡£è¦†ç›–ç‡**: {metrics.doc_coverage:.1f}%

### ğŸ“¦ ä¾èµ–ç®¡ç†
- **ç›´æ¥ä¾èµ–æ•°**: {metrics.dependency_count}
- **å®‰å…¨é—®é¢˜**: {metrics.security_issues}

### âš¡ æ€§èƒ½
- **æ€§èƒ½åˆ†æ•°**: {metrics.performance_score:.1f}/100

## ğŸ¯ è´¨é‡ç­‰çº§

{self._get_quality_grade(quality_score)}

## ğŸ“‹ æ”¹è¿›å»ºè®®

{self._get_improvement_suggestions(metrics)}

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {self._get_timestamp()}*
"""
        return report
    
    def _calculate_quality_score(self, metrics: QualityMetrics) -> float:
        """è®¡ç®—è´¨é‡åˆ†æ•°"""
        
        # æƒé‡é…ç½®
        weights = {
            'test_coverage': 0.25,
            'clippy_warnings': 0.20,
            'doc_coverage': 0.15,
            'security_issues': 0.20,
            'performance': 0.20
        }
        
        # è®¡ç®—å„é¡¹åˆ†æ•°
        test_score = min(metrics.test_coverage, 100)
        clippy_score = max(0, 100 - metrics.clippy_warnings * 2)
        doc_score = min(metrics.doc_coverage, 100)
        security_score = max(0, 100 - metrics.security_issues * 10)
        performance_score = metrics.performance_score
        
        # åŠ æƒå¹³å‡
        total_score = (
            test_score * weights['test_coverage'] +
            clippy_score * weights['clippy_warnings'] +
            doc_score * weights['doc_coverage'] +
            security_score * weights['security_issues'] +
            performance_score * weights['performance']
        )
        
        return min(total_score, 100)
    
    def _get_quality_grade(self, score: float) -> str:
        """è·å–è´¨é‡ç­‰çº§"""
        if score >= 90:
            return "ğŸ† **ä¼˜ç§€** - ä»£ç è´¨é‡éå¸¸é«˜ï¼Œå¯ä»¥å‘å¸ƒ"
        elif score >= 80:
            return "âœ… **è‰¯å¥½** - ä»£ç è´¨é‡è‰¯å¥½ï¼Œå»ºè®®å‘å¸ƒ"
        elif score >= 70:
            return "âš ï¸  **ä¸€èˆ¬** - ä»£ç è´¨é‡ä¸€èˆ¬ï¼Œå»ºè®®æ”¹è¿›åå‘å¸ƒ"
        elif score >= 60:
            return "âŒ **è¾ƒå·®** - ä»£ç è´¨é‡è¾ƒå·®ï¼Œéœ€è¦æ”¹è¿›"
        else:
            return "ğŸš« **å¾ˆå·®** - ä»£ç è´¨é‡å¾ˆå·®ï¼Œä¸å»ºè®®å‘å¸ƒ"
    
    def _get_improvement_suggestions(self, metrics: QualityMetrics) -> str:
        """è·å–æ”¹è¿›å»ºè®®"""
        suggestions = []
        
        if metrics.test_coverage < 80:
            suggestions.append("- ğŸ“ˆ æé«˜æµ‹è¯•è¦†ç›–ç‡åˆ° 80% ä»¥ä¸Š")
        
        if metrics.clippy_warnings > 10:
            suggestions.append("- ğŸ”§ ä¿®å¤ Clippy è­¦å‘Šï¼Œä¿æŒä»£ç æ•´æ´")
        
        if metrics.doc_coverage < 90:
            suggestions.append("- ğŸ“š å®Œå–„ API æ–‡æ¡£ï¼Œæé«˜æ–‡æ¡£è¦†ç›–ç‡")
        
        if metrics.security_issues > 0:
            suggestions.append("- ğŸ”’ ä¿®å¤å®‰å…¨æ¼æ´ï¼Œç¡®ä¿ä»£ç å®‰å…¨")
        
        if metrics.dependency_count > 50:
            suggestions.append("- ğŸ“¦ è€ƒè™‘å‡å°‘ä¾èµ–æ•°é‡ï¼Œç®€åŒ–ä¾èµ–æ ‘")
        
        if not suggestions:
            suggestions.append("- ğŸ‰ ä»£ç è´¨é‡å¾ˆå¥½ï¼Œç»§ç»­ä¿æŒï¼")
        
        return "\n".join(suggestions)
    
    def _get_timestamp(self) -> str:
        """è·å–æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def main():
    parser = argparse.ArgumentParser(description='LumosAI å‘å¸ƒè´¨é‡æ£€æŸ¥å·¥å…·')
    parser.add_argument('--workspace', type=Path, default=Path.cwd(),
                       help='å·¥ä½œç©ºé—´æ ¹ç›®å½•')
    parser.add_argument('--output', type=Path,
                       help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--format', choices=['text', 'json', 'html'],
                       default='text', help='è¾“å‡ºæ ¼å¼')
    parser.add_argument('--threshold', type=float, default=70.0,
                       help='è´¨é‡åˆ†æ•°é˜ˆå€¼')
    
    args = parser.parse_args()
    
    try:
        checker = QualityChecker(args.workspace)
        metrics = checker.run_all_checks()
        
        print("\n" + "=" * 50)
        print("ğŸ“Š è´¨é‡æ£€æŸ¥å®Œæˆ")
        
        # ç”ŸæˆæŠ¥å‘Š
        if args.format == 'text':
            report = checker.generate_report(metrics)
            print(report)
            
            if args.output:
                with open(args.output, 'w', encoding='utf-8') as f:
                    f.write(report)
                print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ° {args.output}")
        
        elif args.format == 'json':
            import json
            report_data = {
                'metrics': metrics.__dict__,
                'quality_score': checker._calculate_quality_score(metrics),
                'timestamp': checker._get_timestamp()
            }
            
            if args.output:
                with open(args.output, 'w', encoding='utf-8') as f:
                    json.dump(report_data, f, indent=2, ensure_ascii=False)
                print(f"âœ… JSON æŠ¥å‘Šå·²ä¿å­˜åˆ° {args.output}")
            else:
                print(json.dumps(report_data, indent=2, ensure_ascii=False))
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°é˜ˆå€¼
        quality_score = checker._calculate_quality_score(metrics)
        if quality_score < args.threshold:
            print(f"\nâŒ è´¨é‡åˆ†æ•° {quality_score:.1f} ä½äºé˜ˆå€¼ {args.threshold}")
            sys.exit(1)
        else:
            print(f"\nâœ… è´¨é‡åˆ†æ•° {quality_score:.1f} è¾¾åˆ°é˜ˆå€¼ {args.threshold}")
    
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        sys.exit(1)

if __name__ == '__main__':
    main()
