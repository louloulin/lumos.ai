use std::collections::HashMap;

/// æµ‹è¯•æ•°æ®é›†
pub struct TestDataSets {
    pub small_documents: Vec<&'static str>,
    pub large_documents: Vec<String>,
    pub multilingual_content: HashMap<String, Vec<&'static str>>,
    pub edge_cases: Vec<&'static str>,
}

impl TestDataSets {
    pub fn load() -> Self {
        Self {
            small_documents: Self::get_small_documents(),
            large_documents: Self::generate_large_documents(),
            multilingual_content: Self::load_multilingual_data(),
            edge_cases: Self::get_edge_cases(),
        }
    }
    
    fn get_small_documents() -> Vec<&'static str> {
        vec![
            "Python is a high-level programming language.",
            "Machine learning is a subset of artificial intelligence.",
            "Deep learning uses neural networks with multiple layers.",
            "Natural language processing deals with text analysis.",
            "Computer vision enables machines to interpret visual information.",
            "Reinforcement learning learns through trial and error.",
            "Data science combines statistics and programming.",
            "Cloud computing provides on-demand computing resources.",
        ]
    }
    
    fn generate_large_documents() -> Vec<String> {
        vec![
            "Large document content ".repeat(1000),
            "Another large document with different content ".repeat(800),
            "Third large document for testing purposes ".repeat(1200),
        ]
    }
    
    fn load_multilingual_data() -> HashMap<String, Vec<&'static str>> {
        let mut data = HashMap::new();
        
        data.insert("chinese".to_string(), vec![
            "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ã€‚",
            "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é¢†åŸŸã€‚",
            "æ·±åº¦å­¦ä¹ ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œã€‚",
            "è‡ªç„¶è¯­è¨€å¤„ç†å¤„ç†æ–‡æœ¬åˆ†æã€‚",
        ]);
        
        data.insert("english".to_string(), vec![
            "Artificial intelligence is a branch of computer science.",
            "Machine learning is a subfield of artificial intelligence.",
            "Deep learning uses multi-layer neural networks.",
            "Natural language processing handles text analysis.",
        ]);
        
        data.insert("japanese".to_string(), vec![
            "äººå·¥çŸ¥èƒ½ã¯ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®ä¸€åˆ†é‡ã§ã™ã€‚",
            "æ©Ÿæ¢°å­¦ç¿’ã¯äººå·¥çŸ¥èƒ½ã®ã‚µãƒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã§ã™ã€‚",
            "ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¯å¤šå±¤ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚",
        ]);
        
        data
    }
    
    fn get_edge_cases() -> Vec<&'static str> {
        vec![
            "", // ç©ºæ–‡æ¡£
            "a", // å•å­—ç¬¦
            "ğŸš€ğŸ¯ğŸ”¥", // ç‰¹æ®Šå­—ç¬¦
            "   ", // ç©ºç™½å­—ç¬¦
            "\n\n\n", // æ¢è¡Œç¬¦
            "A".repeat(10000).leak(), // è¶…é•¿æ–‡æ¡£
            "Mixed ä¸­æ–‡ English æ—¥æœ¬èª content", // æ··åˆè¯­è¨€
            "Special chars: @#$%^&*()_+-=[]{}|;':\",./<>?", // ç‰¹æ®Šç¬¦å·
        ]
    }
}

/// æµ‹è¯•æŸ¥è¯¢æ•°æ®
pub struct TestQueries;

impl TestQueries {
    /// è·å–æµ‹è¯•æŸ¥è¯¢é›†
    pub fn get_test_queries() -> Vec<(&'static str, Vec<usize>)> {
        vec![
            ("programming language", vec![0]),
            ("artificial intelligence", vec![1, 2]),
            ("neural networks", vec![2]),
            ("machine learning", vec![1]),
            ("text analysis", vec![3]),
            ("computer vision", vec![4]),
            ("data science", vec![6]),
            ("cloud computing", vec![7]),
        ]
    }
    
    /// è·å–ä¸­æ–‡æŸ¥è¯¢é›†
    pub fn get_chinese_queries() -> Vec<(&'static str, Vec<usize>)> {
        vec![
            ("äººå·¥æ™ºèƒ½", vec![0, 1]),
            ("æœºå™¨å­¦ä¹ ", vec![1]),
            ("ç¥ç»ç½‘ç»œ", vec![2]),
            ("æ–‡æœ¬åˆ†æ", vec![3]),
        ]
    }
    
    /// è·å–å¤æ‚æŸ¥è¯¢é›†
    pub fn get_complex_queries() -> Vec<&'static str> {
        vec![
            "What is the relationship between machine learning and artificial intelligence?",
            "How do neural networks work in deep learning?",
            "Compare supervised and unsupervised learning methods",
            "Explain the applications of natural language processing",
            "What are the challenges in computer vision?",
        ]
    }
}

/// æ€§èƒ½æµ‹è¯•æ•°æ®
pub struct PerformanceTestData;

impl PerformanceTestData {
    /// è·å–ä¸åŒå¤§å°çš„æ–‡æ¡£é›†åˆ
    pub fn get_document_sets() -> HashMap<String, Vec<String>> {
        let mut sets = HashMap::new();
        
        // å°æ–‡æ¡£é›† (100ä¸ªæ–‡æ¡£ï¼Œæ¯ä¸ª100å­—ç¬¦)
        sets.insert("small".to_string(), 
            (0..100).map(|i| format!("Small document {} content ", i).repeat(10)).collect()
        );
        
        // ä¸­ç­‰æ–‡æ¡£é›† (50ä¸ªæ–‡æ¡£ï¼Œæ¯ä¸ª1000å­—ç¬¦)
        sets.insert("medium".to_string(),
            (0..50).map(|i| format!("Medium document {} content ", i).repeat(100)).collect()
        );
        
        // å¤§æ–‡æ¡£é›† (10ä¸ªæ–‡æ¡£ï¼Œæ¯ä¸ª10000å­—ç¬¦)
        sets.insert("large".to_string(),
            (0..10).map(|i| format!("Large document {} content ", i).repeat(1000)).collect()
        );
        
        sets
    }
    
    /// è·å–å¹¶å‘æµ‹è¯•æŸ¥è¯¢
    pub fn get_concurrent_queries() -> Vec<String> {
        (0..100).map(|i| format!("Concurrent query number {}", i)).collect()
    }
}

/// é”™è¯¯æµ‹è¯•æ•°æ®
pub struct ErrorTestData;

impl ErrorTestData {
    /// è·å–æ— æ•ˆè¾“å…¥æ•°æ®
    pub fn get_invalid_inputs() -> Vec<String> {
        vec![
            "".to_string(), // ç©ºè¾“å…¥
            "\0".to_string(), // ç©ºå­—ç¬¦
            "ï¿½".to_string(), // æ— æ•ˆUTF-8
            "x".repeat(1000), // å¤§è¾“å…¥ï¼ˆå‡å°å¤§å°é¿å…å†…å­˜é—®é¢˜ï¼‰
        ]
    }
    
    /// è·å–è¾¹ç•Œæ¡ä»¶æ•°æ®
    pub fn get_boundary_conditions() -> Vec<(String, String)> {
        vec![
            ("empty_string".to_string(), "".to_string()),
            ("single_char".to_string(), "a".to_string()),
            ("max_length".to_string(), "x".repeat(65536)),
            ("unicode_mixed".to_string(), "Hello ä¸–ç•Œ ğŸŒ".to_string()),
        ]
    }
}
